2018-04-06 13:27:25,139: Tracking: tracking
2018-04-06 13:27:25,139: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1515249b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1515249a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1515249d50>], 'label': 'start'}
2018-04-06 13:27:25,545: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 13:27:25,565: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 13:27:25,567: Parsing core.sql
2018-04-06 13:27:25,586: Parsing materializations/view.sql
2018-04-06 13:27:25,604: Parsing materializations/bigquery.sql
2018-04-06 13:27:25,620: Parsing materializations/wrapper.sql
2018-04-06 13:27:25,625: Parsing materializations/helpers.sql
2018-04-06 13:27:25,645: Parsing materializations/table.sql
2018-04-06 13:27:25,666: Parsing materializations/archive.sql
2018-04-06 13:27:25,706: Parsing materializations/incremental.sql
2018-04-06 13:27:25,739: Parsing etc/get_custom_schema.sql
2018-04-06 13:27:25,745: Parsing adapters/bigquery.sql
2018-04-06 13:27:25,751: Parsing adapters/common.sql
2018-04-06 13:27:25,776: Parsing adapters/redshift.sql
2018-04-06 13:27:25,806: Parsing adapters/postgres.sql
2018-04-06 13:27:25,809: Parsing schema_tests/relationships.sql
2018-04-06 13:27:25,813: Parsing schema_tests/not_null.sql
2018-04-06 13:27:25,815: Parsing schema_tests/unique.sql
2018-04-06 13:27:25,817: Parsing schema_tests/accepted_values.sql
2018-04-06 13:27:25,824: Parsing model.bin_loc_history.fl_empty_groups
2018-04-06 13:27:25,826: Parsing model.bin_loc_history.location_history
2018-04-06 13:27:25,830: Found 42 macros, 0 analyses, 0 archives, 0 tests, 2 models, 0 operations
2018-04-06 13:27:25,833: 
2018-04-06 13:27:25,839: 13:27:25 | Concurrency: 1 threads (target='dev')
2018-04-06 13:27:25,839: 13:27:25 | 
2018-04-06 13:27:25,839: Acquiring new postgres connection "master".
2018-04-06 13:27:25,839: Opening a new connection (0 currently allocated)
2018-04-06 13:27:25,848: Using postgres connection "master".
2018-04-06 13:27:25,848: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 13:27:25,871: SQL status: SELECT 0 in 0.02 seconds
2018-04-06 13:27:25,877: Compiling model.bin_loc_history.fl_empty_groups
2018-04-06 13:27:25,884: Writing injected SQL for node "model.bin_loc_history.fl_empty_groups"
2018-04-06 13:27:25,885: Compiling model.bin_loc_history.location_history
2018-04-06 13:27:25,894: Writing injected SQL for node "model.bin_loc_history.location_history"
2018-04-06 13:27:25,982: Connection 'master' was left open.
2018-04-06 13:27:25,983: 13:27:25 | Done.
2018-04-06 13:27:25,983: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b4a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11327b2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1515238d10>], 'label': 'end'}
2018-04-06 13:27:26,321: Flushing usage events
2018-04-06 13:27:35,457: Tracking: tracking
2018-04-06 13:27:35,458: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b5b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b5a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b5d50>], 'label': 'start'}
2018-04-06 13:27:35,798: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 13:27:35,812: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 13:27:35,814: Parsing core.sql
2018-04-06 13:27:35,828: Parsing materializations/view.sql
2018-04-06 13:27:35,845: Parsing materializations/bigquery.sql
2018-04-06 13:27:35,860: Parsing materializations/wrapper.sql
2018-04-06 13:27:35,864: Parsing materializations/helpers.sql
2018-04-06 13:27:35,884: Parsing materializations/table.sql
2018-04-06 13:27:35,904: Parsing materializations/archive.sql
2018-04-06 13:27:35,939: Parsing materializations/incremental.sql
2018-04-06 13:27:35,969: Parsing etc/get_custom_schema.sql
2018-04-06 13:27:35,975: Parsing adapters/bigquery.sql
2018-04-06 13:27:35,980: Parsing adapters/common.sql
2018-04-06 13:27:36,003: Parsing adapters/redshift.sql
2018-04-06 13:27:36,026: Parsing adapters/postgres.sql
2018-04-06 13:27:36,030: Parsing schema_tests/relationships.sql
2018-04-06 13:27:36,032: Parsing schema_tests/not_null.sql
2018-04-06 13:27:36,034: Parsing schema_tests/unique.sql
2018-04-06 13:27:36,036: Parsing schema_tests/accepted_values.sql
2018-04-06 13:27:36,043: Parsing model.bin_loc_history.fl_empty_groups
2018-04-06 13:27:36,046: Parsing model.bin_loc_history.location_history
2018-04-06 13:27:36,050: Found 42 macros, 0 analyses, 0 archives, 0 tests, 2 models, 0 operations
2018-04-06 13:27:36,053: 
2018-04-06 13:27:36,055: Acquiring new postgres connection "master".
2018-04-06 13:27:36,056: Opening a new connection (0 currently allocated)
2018-04-06 13:27:36,061: Using postgres connection "master".
2018-04-06 13:27:36,061: On master: select distinct nspname from pg_namespace
2018-04-06 13:27:36,063: SQL status: SELECT 10 in 0.00 seconds
2018-04-06 13:27:36,063: Creating schema "dbt_clarice".
2018-04-06 13:27:36,064: Using postgres connection "master".
2018-04-06 13:27:36,064: On master: BEGIN
2018-04-06 13:27:36,065: SQL status: BEGIN in 0.00 seconds
2018-04-06 13:27:36,066: Using postgres connection "master".
2018-04-06 13:27:36,066: On master: create schema if not exists "dbt_clarice"
2018-04-06 13:27:36,076: SQL status: CREATE SCHEMA in 0.01 seconds
2018-04-06 13:27:36,076: On master: COMMIT
2018-04-06 13:27:36,077: Using postgres connection "master".
2018-04-06 13:27:36,077: On master: COMMIT
2018-04-06 13:27:36,079: SQL status: COMMIT in 0.00 seconds
2018-04-06 13:27:36,083: Using postgres connection "master".
2018-04-06 13:27:36,083: On master: BEGIN
2018-04-06 13:27:36,084: SQL status: BEGIN in 0.00 seconds
2018-04-06 13:27:36,084: On master: COMMIT
2018-04-06 13:27:36,084: Using postgres connection "master".
2018-04-06 13:27:36,084: On master: COMMIT
2018-04-06 13:27:36,084: SQL status: COMMIT in 0.00 seconds
2018-04-06 13:27:36,093: 13:27:36 | Concurrency: 1 threads (target='dev')
2018-04-06 13:27:36,094: 13:27:36 | 
2018-04-06 13:27:36,094: Using postgres connection "master".
2018-04-06 13:27:36,094: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 13:27:36,098: SQL status: SELECT 0 in 0.00 seconds
2018-04-06 13:27:36,108: 13:27:36 | 1 of 2 START table model dbt_clarice.fl_empty_groups................. [RUN]
2018-04-06 13:27:36,109: Compiling model.bin_loc_history.fl_empty_groups
2018-04-06 13:27:36,115: Writing injected SQL for node "model.bin_loc_history.fl_empty_groups"
2018-04-06 13:27:36,116: Acquiring new postgres connection "fl_empty_groups".
2018-04-06 13:27:36,116: Opening a new connection (1 currently allocated)
2018-04-06 13:27:36,121: Using postgres connection "fl_empty_groups".
2018-04-06 13:27:36,122: On fl_empty_groups: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 13:27:36,125: SQL status: SELECT 0 in 0.00 seconds
2018-04-06 13:27:36,128: Writing runtime SQL for node "model.bin_loc_history.fl_empty_groups"
2018-04-06 13:27:36,129: Using postgres connection "fl_empty_groups".
2018-04-06 13:27:36,129: On fl_empty_groups: BEGIN
2018-04-06 13:27:36,129: SQL status: BEGIN in 0.00 seconds
2018-04-06 13:27:36,129: Using postgres connection "fl_empty_groups".
2018-04-06 13:27:36,130: On fl_empty_groups: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_empty_groups__dbt_tmp" as (
    

with empty_groups as (
  select ee.dumpster_id,
  d.organization as "org_id",
  lag(ee.occurred_at) over w as "empty_group_start",
  ee.occurred_at as "empty_group_end",
  ee.end_raw_device_data_id,
  row_number() over w as "empty_group"
  from platform.empty_event ee
  inner join platform.dumpster d
  on ee.dumpster_id = d.id
  where ee.was_emptied
  and ee.confidence > 0.5
  window w as (partition by ee.dumpster_id order by ee.occurred_at asc)
)
select dumpster_id,
org_id,
empty_group_start,
empty_group_end,
end_raw_device_data_id,
dumpster_id || '_eg' || empty_group::text as "empty_group_id"
order by 6 desc
  );
2018-04-06 13:27:36,138: Postgres error: column "dumpster_id" does not exist
LINE 26: select dumpster_id,
                ^

2018-04-06 13:27:36,138: On fl_empty_groups: ROLLBACK
2018-04-06 13:27:36,139: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062cd850>], 'label': 'a03e6b65-383c-4df6-bf2f-3fb2e983e464'}
2018-04-06 13:27:36,469: 13:27:36 | 1 of 2 ERROR creating table model dbt_clarice.fl_empty_groups........ [ERROR in 0.03s]
2018-04-06 13:27:36,469: 13:27:36 | 2 of 2 START view model dbt_clarice.location_history................. [RUN]
2018-04-06 13:27:36,470: Compiling model.bin_loc_history.location_history
2018-04-06 13:27:36,475: Writing injected SQL for node "model.bin_loc_history.location_history"
2018-04-06 13:27:36,477: Acquiring new postgres connection "location_history".
2018-04-06 13:27:36,477: Re-using an available connection from the pool.
2018-04-06 13:27:36,477: Using postgres connection "location_history".
2018-04-06 13:27:36,477: On location_history: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 13:27:36,478: SQL status: SELECT 0 in 0.00 seconds
2018-04-06 13:27:36,480: Writing runtime SQL for node "model.bin_loc_history.location_history"
2018-04-06 13:27:36,481: Using postgres connection "location_history".
2018-04-06 13:27:36,481: On location_history: BEGIN
2018-04-06 13:27:36,481: SQL status: BEGIN in 0.00 seconds
2018-04-06 13:27:36,481: Using postgres connection "location_history".
2018-04-06 13:27:36,482: On location_history: 
  
    
  

  
    
  create view "dbt_clarice"."location_history__dbt_tmp" as (
    

select dumpster_id,
location_id,
arrived_at,
lead(arrived_at) over w as "departed_at"
from platform.dumpster_arrival
where is_active
window w as (partition by dumpster_id order by arrived_at asc)
  );
2018-04-06 13:27:36,499: SQL status: CREATE VIEW in 0.02 seconds
2018-04-06 13:27:36,500: Using postgres connection "location_history".
2018-04-06 13:27:36,500: On location_history: alter table "dbt_clarice"."location_history__dbt_tmp" rename to "location_history"
2018-04-06 13:27:36,501: SQL status: ALTER TABLE in 0.00 seconds
2018-04-06 13:27:36,501: On location_history: COMMIT
2018-04-06 13:27:36,501: Using postgres connection "location_history".
2018-04-06 13:27:36,502: On location_history: COMMIT
2018-04-06 13:27:36,502: SQL status: COMMIT in 0.00 seconds
2018-04-06 13:27:36,503: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062cd850>], 'label': 'a03e6b65-383c-4df6-bf2f-3fb2e983e464'}
2018-04-06 13:27:36,844: 13:27:36 | 2 of 2 OK created view model dbt_clarice.location_history............ [CREATE VIEW in 0.03s]
2018-04-06 13:27:36,935: Using postgres connection "master".
2018-04-06 13:27:36,935: On master: BEGIN
2018-04-06 13:27:36,935: SQL status: BEGIN in 0.00 seconds
2018-04-06 13:27:36,936: On master: COMMIT
2018-04-06 13:27:36,936: Using postgres connection "master".
2018-04-06 13:27:36,936: On master: COMMIT
2018-04-06 13:27:36,936: SQL status: COMMIT in 0.00 seconds
2018-04-06 13:27:36,936: 13:27:36 | 
2018-04-06 13:27:36,937: 13:27:36 | Finished running 1 table models, 1 view models in 0.88s.
2018-04-06 13:27:36,937: Connection 'master' was left open.
2018-04-06 13:27:36,937: 
2018-04-06 13:27:36,937: Completed with 1 errors:
2018-04-06 13:27:36,937: 
2018-04-06 13:27:36,938: Database Error in model fl_empty_groups (models/fl_empty_groups.sql)
2018-04-06 13:27:36,938:   column "dumpster_id" does not exist
2018-04-06 13:27:36,938:   LINE 26: select dumpster_id,
2018-04-06 13:27:36,938:                   ^
2018-04-06 13:27:36,940:   compiled SQL at target/run/bin_loc_history/fl_empty_groups.sql
2018-04-06 13:27:36,940: 
Done. PASS=1 ERROR=1 SKIP=0 TOTAL=2
2018-04-06 13:27:36,940: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1031e2710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049122d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062d9dd0>], 'label': 'end'}
2018-04-06 13:27:37,281: Flushing usage events
2018-04-06 13:28:01,292: Tracking: tracking
2018-04-06 13:28:01,292: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150a484b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150a484a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150a484d50>], 'label': 'start'}
2018-04-06 13:28:01,641: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 13:28:01,656: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 13:28:01,657: Parsing core.sql
2018-04-06 13:28:01,671: Parsing materializations/view.sql
2018-04-06 13:28:01,687: Parsing materializations/bigquery.sql
2018-04-06 13:28:01,702: Parsing materializations/wrapper.sql
2018-04-06 13:28:01,705: Parsing materializations/helpers.sql
2018-04-06 13:28:01,725: Parsing materializations/table.sql
2018-04-06 13:28:01,745: Parsing materializations/archive.sql
2018-04-06 13:28:01,780: Parsing materializations/incremental.sql
2018-04-06 13:28:01,814: Parsing etc/get_custom_schema.sql
2018-04-06 13:28:01,820: Parsing adapters/bigquery.sql
2018-04-06 13:28:01,825: Parsing adapters/common.sql
2018-04-06 13:28:01,848: Parsing adapters/redshift.sql
2018-04-06 13:28:01,871: Parsing adapters/postgres.sql
2018-04-06 13:28:01,874: Parsing schema_tests/relationships.sql
2018-04-06 13:28:01,876: Parsing schema_tests/not_null.sql
2018-04-06 13:28:01,878: Parsing schema_tests/unique.sql
2018-04-06 13:28:01,880: Parsing schema_tests/accepted_values.sql
2018-04-06 13:28:01,886: Parsing model.bin_loc_history.fl_empty_groups
2018-04-06 13:28:01,888: Parsing model.bin_loc_history.location_history
2018-04-06 13:28:01,893: Found 42 macros, 0 analyses, 0 archives, 0 tests, 2 models, 0 operations
2018-04-06 13:28:01,896: 
2018-04-06 13:28:01,899: Acquiring new postgres connection "master".
2018-04-06 13:28:01,899: Opening a new connection (0 currently allocated)
2018-04-06 13:28:01,904: Using postgres connection "master".
2018-04-06 13:28:01,904: On master: select distinct nspname from pg_namespace
2018-04-06 13:28:01,906: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 13:28:01,909: Using postgres connection "master".
2018-04-06 13:28:01,909: On master: BEGIN
2018-04-06 13:28:01,910: SQL status: BEGIN in 0.00 seconds
2018-04-06 13:28:01,910: On master: COMMIT
2018-04-06 13:28:01,910: Using postgres connection "master".
2018-04-06 13:28:01,910: On master: COMMIT
2018-04-06 13:28:01,910: SQL status: COMMIT in 0.00 seconds
2018-04-06 13:28:01,916: 13:28:01 | Concurrency: 1 threads (target='dev')
2018-04-06 13:28:01,916: 13:28:01 | 
2018-04-06 13:28:01,916: Using postgres connection "master".
2018-04-06 13:28:01,917: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 13:28:01,919: SQL status: SELECT 1 in 0.00 seconds
2018-04-06 13:28:01,926: 13:28:01 | 1 of 2 START table model dbt_clarice.fl_empty_groups................. [RUN]
2018-04-06 13:28:01,926: Compiling model.bin_loc_history.fl_empty_groups
2018-04-06 13:28:01,932: Writing injected SQL for node "model.bin_loc_history.fl_empty_groups"
2018-04-06 13:28:01,933: Acquiring new postgres connection "fl_empty_groups".
2018-04-06 13:28:01,933: Opening a new connection (1 currently allocated)
2018-04-06 13:28:01,938: Using postgres connection "fl_empty_groups".
2018-04-06 13:28:01,938: On fl_empty_groups: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 13:28:01,944: SQL status: SELECT 1 in 0.01 seconds
2018-04-06 13:28:01,947: Writing runtime SQL for node "model.bin_loc_history.fl_empty_groups"
2018-04-06 13:28:01,948: Using postgres connection "fl_empty_groups".
2018-04-06 13:28:01,948: On fl_empty_groups: BEGIN
2018-04-06 13:28:01,948: SQL status: BEGIN in 0.00 seconds
2018-04-06 13:28:01,948: Using postgres connection "fl_empty_groups".
2018-04-06 13:28:01,949: On fl_empty_groups: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_empty_groups__dbt_tmp" as (
    

with empty_groups as (
  select ee.dumpster_id,
  d.organization as "org_id",
  lag(ee.occurred_at) over w as "empty_group_start",
  ee.occurred_at as "empty_group_end",
  ee.end_raw_device_data_id,
  row_number() over w as "empty_group"
  from platform.empty_event ee
  inner join platform.dumpster d
  on ee.dumpster_id = d.id
  where ee.was_emptied
  and ee.confidence > 0.5
  window w as (partition by ee.dumpster_id order by ee.occurred_at asc)
)
select dumpster_id,
org_id,
empty_group_start,
empty_group_end,
end_raw_device_data_id,
dumpster_id || '_eg' || empty_group::text as "empty_group_id"
from empty_groups 
order by 6 desc
  );
2018-04-06 13:28:11,497: SQL status: SELECT 215895 in 9.55 seconds
2018-04-06 13:28:11,498: Using postgres connection "fl_empty_groups".
2018-04-06 13:28:11,498: On fl_empty_groups: alter table "dbt_clarice"."fl_empty_groups__dbt_tmp" rename to "fl_empty_groups"
2018-04-06 13:28:11,507: SQL status: ALTER TABLE in 0.01 seconds
2018-04-06 13:28:11,507: On fl_empty_groups: COMMIT
2018-04-06 13:28:11,507: Using postgres connection "fl_empty_groups".
2018-04-06 13:28:11,507: On fl_empty_groups: COMMIT
2018-04-06 13:28:11,512: SQL status: COMMIT in 0.01 seconds
2018-04-06 13:28:11,513: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150a54dc10>], 'label': 'dea6efea-1687-4e1c-81cd-0ff01dceb250'}
2018-04-06 13:28:11,848: 13:28:11 | 1 of 2 OK created table model dbt_clarice.fl_empty_groups............ [SELECT 215895 in 9.59s]
2018-04-06 13:28:11,848: 13:28:11 | 2 of 2 START view model dbt_clarice.location_history................. [RUN]
2018-04-06 13:28:11,848: Compiling model.bin_loc_history.location_history
2018-04-06 13:28:11,856: Writing injected SQL for node "model.bin_loc_history.location_history"
2018-04-06 13:28:11,858: Acquiring new postgres connection "location_history".
2018-04-06 13:28:11,858: Re-using an available connection from the pool.
2018-04-06 13:28:11,859: Using postgres connection "location_history".
2018-04-06 13:28:11,859: On location_history: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 13:28:11,860: SQL status: SELECT 2 in 0.00 seconds
2018-04-06 13:28:11,862: Writing runtime SQL for node "model.bin_loc_history.location_history"
2018-04-06 13:28:11,863: Using postgres connection "location_history".
2018-04-06 13:28:11,863: On location_history: BEGIN
2018-04-06 13:28:11,863: SQL status: BEGIN in 0.00 seconds
2018-04-06 13:28:11,863: Using postgres connection "location_history".
2018-04-06 13:28:11,863: On location_history: 
  
    
  

  
    
  create view "dbt_clarice"."location_history__dbt_tmp" as (
    

select dumpster_id,
location_id,
arrived_at,
lead(arrived_at) over w as "departed_at"
from platform.dumpster_arrival
where is_active
window w as (partition by dumpster_id order by arrived_at asc)
  );
2018-04-06 13:28:11,865: SQL status: CREATE VIEW in 0.00 seconds
2018-04-06 13:28:11,865: Using postgres connection "location_history".
2018-04-06 13:28:11,865: On location_history: drop view if exists "dbt_clarice"."location_history" cascade
2018-04-06 13:28:11,875: SQL status: DROP VIEW in 0.01 seconds
2018-04-06 13:28:11,875: Using postgres connection "location_history".
2018-04-06 13:28:11,876: On location_history: alter table "dbt_clarice"."location_history__dbt_tmp" rename to "location_history"
2018-04-06 13:28:11,876: SQL status: ALTER TABLE in 0.00 seconds
2018-04-06 13:28:11,877: On location_history: COMMIT
2018-04-06 13:28:11,877: Using postgres connection "location_history".
2018-04-06 13:28:11,877: On location_history: COMMIT
2018-04-06 13:28:11,878: SQL status: COMMIT in 0.00 seconds
2018-04-06 13:28:11,878: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150a59c9d0>], 'label': 'dea6efea-1687-4e1c-81cd-0ff01dceb250'}
2018-04-06 13:28:12,214: 13:28:12 | 2 of 2 OK created view model dbt_clarice.location_history............ [CREATE VIEW in 0.03s]
2018-04-06 13:28:12,322: Using postgres connection "master".
2018-04-06 13:28:12,322: On master: BEGIN
2018-04-06 13:28:12,323: SQL status: BEGIN in 0.00 seconds
2018-04-06 13:28:12,323: On master: COMMIT
2018-04-06 13:28:12,323: Using postgres connection "master".
2018-04-06 13:28:12,323: On master: COMMIT
2018-04-06 13:28:12,323: SQL status: COMMIT in 0.00 seconds
2018-04-06 13:28:12,323: 13:28:12 | 
2018-04-06 13:28:12,324: 13:28:12 | Finished running 1 table models, 1 view models in 10.43s.
2018-04-06 13:28:12,324: Connection 'master' was left open.
2018-04-06 13:28:12,324: 
2018-04-06 13:28:12,324: Completed successfully
2018-04-06 13:28:12,324: 
Done. PASS=2 ERROR=0 SKIP=0 TOTAL=2
2018-04-06 13:28:12,325: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ce8710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084b62d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150a474d10>], 'label': 'end'}
2018-04-06 13:28:12,673: Flushing usage events
2018-04-06 15:50:01,238: Tracking: tracking
2018-04-06 15:50:01,239: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e16bb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e16ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e16bd50>], 'label': 'start'}
2018-04-06 15:50:01,637: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 15:50:01,652: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 15:50:01,653: Parsing core.sql
2018-04-06 15:50:01,668: Parsing materializations/view.sql
2018-04-06 15:50:01,685: Parsing materializations/bigquery.sql
2018-04-06 15:50:01,703: Parsing materializations/wrapper.sql
2018-04-06 15:50:01,707: Parsing materializations/helpers.sql
2018-04-06 15:50:01,727: Parsing materializations/table.sql
2018-04-06 15:50:01,749: Parsing materializations/archive.sql
2018-04-06 15:50:01,787: Parsing materializations/incremental.sql
2018-04-06 15:50:01,817: Parsing etc/get_custom_schema.sql
2018-04-06 15:50:01,823: Parsing adapters/bigquery.sql
2018-04-06 15:50:01,832: Parsing adapters/common.sql
2018-04-06 15:50:01,856: Parsing adapters/redshift.sql
2018-04-06 15:50:01,880: Parsing adapters/postgres.sql
2018-04-06 15:50:01,884: Parsing schema_tests/relationships.sql
2018-04-06 15:50:01,887: Parsing schema_tests/not_null.sql
2018-04-06 15:50:01,889: Parsing schema_tests/unique.sql
2018-04-06 15:50:01,891: Parsing schema_tests/accepted_values.sql
2018-04-06 15:50:01,900: Parsing model.bin_loc_history.fl_empty_groups
2018-04-06 15:50:01,903: Parsing model.bin_loc_history.location_history
2018-04-06 15:50:01,905: Parsing model.bin_loc_history.post_history
2018-04-06 15:50:01,909: Found 42 macros, 0 analyses, 0 archives, 0 tests, 3 models, 0 operations
2018-04-06 15:50:01,912: 
2018-04-06 15:50:01,917: 15:50:01 | Concurrency: 1 threads (target='dev')
2018-04-06 15:50:01,917: 15:50:01 | 
2018-04-06 15:50:01,918: Acquiring new postgres connection "master".
2018-04-06 15:50:01,918: Opening a new connection (0 currently allocated)
2018-04-06 15:50:01,924: Using postgres connection "master".
2018-04-06 15:50:01,924: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 15:50:01,927: SQL status: SELECT 2 in 0.00 seconds
2018-04-06 15:50:01,937: Compiling model.bin_loc_history.fl_empty_groups
2018-04-06 15:50:01,941: Writing injected SQL for node "model.bin_loc_history.fl_empty_groups"
2018-04-06 15:50:01,942: Compiling model.bin_loc_history.location_history
2018-04-06 15:50:01,950: Writing injected SQL for node "model.bin_loc_history.location_history"
2018-04-06 15:50:01,951: Compiling model.bin_loc_history.post_history
2018-04-06 15:50:01,959: Writing injected SQL for node "model.bin_loc_history.post_history"
2018-04-06 15:50:02,039: Connection 'master' was left open.
2018-04-06 15:50:02,039: 15:50:02 | Done.
2018-04-06 15:50:02,039: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b197710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8c82d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e15ad10>], 'label': 'end'}
2018-04-06 15:50:02,374: Flushing usage events
2018-04-06 15:50:08,964: Tracking: tracking
2018-04-06 15:50:08,964: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1512ff7b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1512ff7a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1512ff7d50>], 'label': 'start'}
2018-04-06 15:50:09,311: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 15:50:09,325: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 15:50:09,327: Parsing core.sql
2018-04-06 15:50:09,340: Parsing materializations/view.sql
2018-04-06 15:50:09,357: Parsing materializations/bigquery.sql
2018-04-06 15:50:09,374: Parsing materializations/wrapper.sql
2018-04-06 15:50:09,378: Parsing materializations/helpers.sql
2018-04-06 15:50:09,398: Parsing materializations/table.sql
2018-04-06 15:50:09,420: Parsing materializations/archive.sql
2018-04-06 15:50:09,456: Parsing materializations/incremental.sql
2018-04-06 15:50:09,489: Parsing etc/get_custom_schema.sql
2018-04-06 15:50:09,495: Parsing adapters/bigquery.sql
2018-04-06 15:50:09,500: Parsing adapters/common.sql
2018-04-06 15:50:09,523: Parsing adapters/redshift.sql
2018-04-06 15:50:09,547: Parsing adapters/postgres.sql
2018-04-06 15:50:09,550: Parsing schema_tests/relationships.sql
2018-04-06 15:50:09,553: Parsing schema_tests/not_null.sql
2018-04-06 15:50:09,554: Parsing schema_tests/unique.sql
2018-04-06 15:50:09,556: Parsing schema_tests/accepted_values.sql
2018-04-06 15:50:09,563: Parsing model.bin_loc_history.fl_empty_groups
2018-04-06 15:50:09,565: Parsing model.bin_loc_history.location_history
2018-04-06 15:50:09,567: Parsing model.bin_loc_history.post_history
2018-04-06 15:50:09,571: Found 42 macros, 0 analyses, 0 archives, 0 tests, 3 models, 0 operations
2018-04-06 15:50:09,574: 
2018-04-06 15:50:09,577: Acquiring new postgres connection "master".
2018-04-06 15:50:09,578: Opening a new connection (0 currently allocated)
2018-04-06 15:50:09,583: Using postgres connection "master".
2018-04-06 15:50:09,583: On master: select distinct nspname from pg_namespace
2018-04-06 15:50:09,585: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 15:50:09,588: Using postgres connection "master".
2018-04-06 15:50:09,588: On master: BEGIN
2018-04-06 15:50:09,589: SQL status: BEGIN in 0.00 seconds
2018-04-06 15:50:09,590: On master: COMMIT
2018-04-06 15:50:09,590: Using postgres connection "master".
2018-04-06 15:50:09,590: On master: COMMIT
2018-04-06 15:50:09,590: SQL status: COMMIT in 0.00 seconds
2018-04-06 15:50:09,596: 15:50:09 | Concurrency: 1 threads (target='dev')
2018-04-06 15:50:09,596: 15:50:09 | 
2018-04-06 15:50:09,596: Using postgres connection "master".
2018-04-06 15:50:09,596: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 15:50:09,599: SQL status: SELECT 2 in 0.00 seconds
2018-04-06 15:50:09,609: 15:50:09 | 1 of 3 START table model dbt_clarice.fl_empty_groups................. [RUN]
2018-04-06 15:50:09,609: Compiling model.bin_loc_history.fl_empty_groups
2018-04-06 15:50:09,615: Writing injected SQL for node "model.bin_loc_history.fl_empty_groups"
2018-04-06 15:50:09,616: Acquiring new postgres connection "fl_empty_groups".
2018-04-06 15:50:09,616: Opening a new connection (1 currently allocated)
2018-04-06 15:50:09,621: Using postgres connection "fl_empty_groups".
2018-04-06 15:50:09,621: On fl_empty_groups: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 15:50:09,627: SQL status: SELECT 2 in 0.01 seconds
2018-04-06 15:50:09,629: Writing runtime SQL for node "model.bin_loc_history.fl_empty_groups"
2018-04-06 15:50:09,630: Using postgres connection "fl_empty_groups".
2018-04-06 15:50:09,630: On fl_empty_groups: BEGIN
2018-04-06 15:50:09,630: SQL status: BEGIN in 0.00 seconds
2018-04-06 15:50:09,631: Using postgres connection "fl_empty_groups".
2018-04-06 15:50:09,631: On fl_empty_groups: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_empty_groups__dbt_tmp" as (
    

with empty_groups as (
  select ee.dumpster_id,
  d.organization as "org_id",
  lag(ee.occurred_at) over w as "empty_group_start",
  ee.occurred_at as "empty_group_end",
  ee.end_raw_device_data_id,
  row_number() over w as "empty_group",
  ee.updated_at -- placeholder, may want different logic for this later
  from platform.empty_event ee
  inner join platform.dumpster d
  on ee.dumpster_id = d.id
  where ee.was_emptied
  and ee.confidence > 0.5
  window w as (partition by ee.dumpster_id order by ee.occurred_at asc)
)
select dumpster_id,
org_id,
empty_group_start,
empty_group_end,
end_raw_device_data_id,
dumpster_id || '_eg' || empty_group::text as "empty_group_id",
updated_at
from empty_groups
order by 6 desc
  );
2018-04-06 15:50:18,632: SQL status: SELECT 215895 in 9.00 seconds
2018-04-06 15:50:18,633: Using postgres connection "fl_empty_groups".
2018-04-06 15:50:18,633: On fl_empty_groups: drop table if exists "dbt_clarice"."fl_empty_groups" cascade
2018-04-06 15:50:18,634: SQL status: DROP TABLE in 0.00 seconds
2018-04-06 15:50:18,635: Using postgres connection "fl_empty_groups".
2018-04-06 15:50:18,635: On fl_empty_groups: alter table "dbt_clarice"."fl_empty_groups__dbt_tmp" rename to "fl_empty_groups"
2018-04-06 15:50:18,643: SQL status: ALTER TABLE in 0.01 seconds
2018-04-06 15:50:18,643: On fl_empty_groups: COMMIT
2018-04-06 15:50:18,643: Using postgres connection "fl_empty_groups".
2018-04-06 15:50:18,643: On fl_empty_groups: COMMIT
2018-04-06 15:50:18,652: SQL status: COMMIT in 0.01 seconds
2018-04-06 15:50:18,653: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15130c0250>], 'label': '46b667d5-18de-4973-980c-0a9142aa2107'}
2018-04-06 15:50:19,019: 15:50:19 | 1 of 3 OK created table model dbt_clarice.fl_empty_groups............ [SELECT 215895 in 9.04s]
2018-04-06 15:50:19,020: 15:50:19 | 2 of 3 START table model dbt_clarice.location_history................ [RUN]
2018-04-06 15:50:19,020: Compiling model.bin_loc_history.location_history
2018-04-06 15:50:19,025: Writing injected SQL for node "model.bin_loc_history.location_history"
2018-04-06 15:50:19,026: Acquiring new postgres connection "location_history".
2018-04-06 15:50:19,027: Re-using an available connection from the pool.
2018-04-06 15:50:19,027: Using postgres connection "location_history".
2018-04-06 15:50:19,027: On location_history: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 15:50:19,028: SQL status: SELECT 2 in 0.00 seconds
2018-04-06 15:50:19,031: Writing runtime SQL for node "model.bin_loc_history.location_history"
2018-04-06 15:50:19,031: Using postgres connection "location_history".
2018-04-06 15:50:19,032: On location_history: BEGIN
2018-04-06 15:50:19,032: SQL status: BEGIN in 0.00 seconds
2018-04-06 15:50:19,032: Using postgres connection "location_history".
2018-04-06 15:50:19,032: On location_history: 
  
    
  

  
    
  create  table
    "dbt_clarice"."location_history__dbt_tmp" as (
    

select dumpster_id,
location_id,
arrived_at,
lead(arrived_at) over w as "departed_at"
from platform.dumpster_arrival
where is_active
window w as (partition by dumpster_id order by arrived_at asc)
  );
2018-04-06 15:50:23,921: SQL status: SELECT 187799 in 4.89 seconds
2018-04-06 15:50:23,922: Using postgres connection "location_history".
2018-04-06 15:50:23,922: On location_history: drop view if exists "dbt_clarice"."location_history" cascade
2018-04-06 15:50:23,923: SQL status: DROP VIEW in 0.00 seconds
2018-04-06 15:50:23,923: Using postgres connection "location_history".
2018-04-06 15:50:23,923: On location_history: alter table "dbt_clarice"."location_history__dbt_tmp" rename to "location_history"
2018-04-06 15:50:23,926: SQL status: ALTER TABLE in 0.00 seconds
2018-04-06 15:50:23,926: On location_history: COMMIT
2018-04-06 15:50:23,926: Using postgres connection "location_history".
2018-04-06 15:50:23,926: On location_history: COMMIT
2018-04-06 15:50:23,929: SQL status: COMMIT in 0.00 seconds
2018-04-06 15:50:23,930: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15130bcb90>], 'label': '46b667d5-18de-4973-980c-0a9142aa2107'}
2018-04-06 15:50:24,262: 15:50:24 | 2 of 3 OK created table model dbt_clarice.location_history........... [SELECT 187799 in 4.91s]
2018-04-06 15:50:24,262: 15:50:24 | 3 of 3 START table model dbt_clarice.post_history.................... [RUN]
2018-04-06 15:50:24,263: Compiling model.bin_loc_history.post_history
2018-04-06 15:50:24,269: Writing injected SQL for node "model.bin_loc_history.post_history"
2018-04-06 15:50:24,270: Acquiring new postgres connection "post_history".
2018-04-06 15:50:24,270: Re-using an available connection from the pool.
2018-04-06 15:50:24,270: Using postgres connection "post_history".
2018-04-06 15:50:24,270: On post_history: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 15:50:24,271: SQL status: SELECT 2 in 0.00 seconds
2018-04-06 15:50:24,274: Writing runtime SQL for node "model.bin_loc_history.post_history"
2018-04-06 15:50:24,275: Using postgres connection "post_history".
2018-04-06 15:50:24,275: On post_history: BEGIN
2018-04-06 15:50:24,276: SQL status: BEGIN in 0.00 seconds
2018-04-06 15:50:24,276: Using postgres connection "post_history".
2018-04-06 15:50:24,276: On post_history: 
  
    
  

  
    
  create  table
    "dbt_clarice"."post_history__dbt_tmp" as (
    

select rdd.id as "raw_device_data_id",
d.organization as "org_id",
rdd.dumpster_id,
d.container_type,
d.dumpster_timezone,
rdd.post_timestamp,
rdd.agg_camera_blocked,
rdd.agg_level,
l.id as "location_id",
l.description as "location_name",
l.type as "location_type",
da.is_active,
rdd.lat,
rdd.lon,
case when rdd.latlon_radius in (0, 70000) then null else rdd.latlon_radius end as "latlon_radius",
case when rdd.latlon_radius < 50 and rdd.latlon_radius != 0 then 1 else 0 end as "good_gps",
firmware,
case
  when firmware like 'oscar-00%' or firmware = 'oscar-lte2' then 'R10'
  when firmware like 'oscar-_1%' then 'R11'
  when firmware like 'oscar-_2%' then 'R12'
  else null end as "sensor_model",
case
  when (rdd.extra_info::json ->> 'wake_reason') = '0' then 'unknown'
  when (rdd.extra_info::json ->> 'wake_reason') = '1' then 'scheduled post'
  when (rdd.extra_info::json ->> 'wake_reason') = '2' then 'accelerometer trigger'
  when (rdd.extra_info::json ->> 'wake_reason') = '3' then 'FW/HW issue'
  when (rdd.extra_info::json ->> 'wake_reason') = '4' then 'power issue'
  when (rdd.extra_info::json ->> 'wake_reason') = '5' then 'reset after programming'
  else null end as "wake_reason",
case
  when rdd.extra_info::json ->> 'accel_int' is null then null
  when rdd.extra_info::json ->> 'accel_int' = 'true' then true
  else false end as "accel_int",
(rdd.extra_info::json ->> 'signal_dbi')::int as "signal_dbi",
(rdd.extra_info::json ->> 'consecutive_failed_wakes')::int as "consecutive_failed_wakes",
(rdd.extra_info::json ->> 'session_count')::int as "session_count",
rdd.errors::text as "errors"
from platform.raw_device_data rdd
inner join platform.dumpster d
on rdd.dumpster_id = d.id
left join platform.dumpster_arrival da
on rdd.id = da.raw_device_data_id
left join platform.location l
on da.location_id = l.id
where not d.is_hidden
and not d.is_hidden_for_org
and not rdd.in_maintenance_mode
  );
2018-04-06 15:57:09,439: SQL status: SELECT 5429233 in 405.16 seconds
2018-04-06 15:57:09,443: Using postgres connection "post_history".
2018-04-06 15:57:09,443: On post_history: alter table "dbt_clarice"."post_history__dbt_tmp" rename to "post_history"
2018-04-06 15:57:09,445: SQL status: ALTER TABLE in 0.00 seconds
2018-04-06 15:57:09,445: On post_history: COMMIT
2018-04-06 15:57:09,445: Using postgres connection "post_history".
2018-04-06 15:57:09,446: On post_history: COMMIT
2018-04-06 15:57:09,447: SQL status: COMMIT in 0.00 seconds
2018-04-06 15:57:09,448: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x151310fe10>], 'label': '46b667d5-18de-4973-980c-0a9142aa2107'}
2018-04-06 15:57:09,826: 15:57:09 | 3 of 3 OK created table model dbt_clarice.post_history............... [SELECT 5429233 in 405.18s]
2018-04-06 15:57:09,892: Using postgres connection "master".
2018-04-06 15:57:09,892: On master: BEGIN
2018-04-06 15:57:09,895: SQL status: BEGIN in 0.00 seconds
2018-04-06 15:57:09,896: On master: COMMIT
2018-04-06 15:57:09,896: Using postgres connection "master".
2018-04-06 15:57:09,896: On master: COMMIT
2018-04-06 15:57:09,896: SQL status: COMMIT in 0.00 seconds
2018-04-06 15:57:09,899: 15:57:09 | 
2018-04-06 15:57:09,899: 15:57:09 | Finished running 3 table models in 420.32s.
2018-04-06 15:57:09,899: Connection 'master' was left open.
2018-04-06 15:57:09,907: 
2018-04-06 15:57:09,908: Completed successfully
2018-04-06 15:57:09,908: 
Done. PASS=3 ERROR=0 SKIP=0 TOTAL=3
2018-04-06 15:57:09,918: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f905710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x151305d510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1512fe7ad0>], 'label': 'end'}
2018-04-06 15:57:10,298: Flushing usage events
2018-04-06 16:34:15,019: Tracking: tracking
2018-04-06 16:34:15,020: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099a3b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099a3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099a3d50>], 'label': 'start'}
2018-04-06 16:34:15,425: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 16:34:15,443: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 16:34:15,445: Parsing core.sql
2018-04-06 16:34:15,460: Parsing materializations/view.sql
2018-04-06 16:34:15,482: Parsing materializations/bigquery.sql
2018-04-06 16:34:15,498: Parsing materializations/wrapper.sql
2018-04-06 16:34:15,502: Parsing materializations/helpers.sql
2018-04-06 16:34:15,528: Parsing materializations/table.sql
2018-04-06 16:34:15,553: Parsing materializations/archive.sql
2018-04-06 16:34:15,592: Parsing materializations/incremental.sql
2018-04-06 16:34:15,624: Parsing etc/get_custom_schema.sql
2018-04-06 16:34:15,632: Parsing adapters/bigquery.sql
2018-04-06 16:34:15,638: Parsing adapters/common.sql
2018-04-06 16:34:15,663: Parsing adapters/redshift.sql
2018-04-06 16:34:15,691: Parsing adapters/postgres.sql
2018-04-06 16:34:15,694: Parsing schema_tests/relationships.sql
2018-04-06 16:34:15,697: Parsing schema_tests/not_null.sql
2018-04-06 16:34:15,699: Parsing schema_tests/unique.sql
2018-04-06 16:34:15,702: Parsing schema_tests/accepted_values.sql
2018-04-06 16:34:15,711: Parsing model.compology.fl_empty_groups
2018-04-06 16:34:15,714: Parsing model.compology.location_history
2018-04-06 16:34:15,716: Parsing model.compology.post_history
2018-04-06 16:34:15,718: Parsing model.compology.fl_level_at_service
2018-04-06 16:34:15,723: Found 42 macros, 0 analyses, 0 archives, 0 tests, 4 models, 0 operations
2018-04-06 16:34:15,727: 
2018-04-06 16:34:15,734: 16:34:15 | Concurrency: 1 threads (target='dev')
2018-04-06 16:34:15,734: 16:34:15 | 
2018-04-06 16:34:15,735: Acquiring new postgres connection "master".
2018-04-06 16:34:15,735: Opening a new connection (0 currently allocated)
2018-04-06 16:34:15,744: Using postgres connection "master".
2018-04-06 16:34:15,744: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 16:34:15,748: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 16:34:15,762: Compiling model.compology.location_history
2018-04-06 16:34:15,769: Writing injected SQL for node "model.compology.location_history"
2018-04-06 16:34:15,770: Compiling model.compology.fl_empty_groups
2018-04-06 16:34:15,775: Writing injected SQL for node "model.compology.fl_empty_groups"
2018-04-06 16:34:15,776: Compiling model.compology.post_history
2018-04-06 16:34:15,786: Writing injected SQL for node "model.compology.post_history"
2018-04-06 16:34:15,788: Compiling model.compology.fl_level_at_service
2018-04-06 16:34:15,797: Writing injected SQL for node "model.compology.fl_level_at_service"
2018-04-06 16:34:15,866: Connection 'master' was left open.
2018-04-06 16:34:15,866: 16:34:15 | Done.
2018-04-06 16:34:15,867: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069cf710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081002d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109992d10>], 'label': 'end'}
2018-04-06 16:34:16,204: Flushing usage events
2018-04-06 16:34:27,416: Tracking: tracking
2018-04-06 16:34:27,416: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2d9b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2d9a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2d9d50>], 'label': 'start'}
2018-04-06 16:34:27,766: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 16:34:27,783: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 16:34:27,784: Parsing core.sql
2018-04-06 16:34:27,799: Parsing materializations/view.sql
2018-04-06 16:34:27,816: Parsing materializations/bigquery.sql
2018-04-06 16:34:27,833: Parsing materializations/wrapper.sql
2018-04-06 16:34:27,837: Parsing materializations/helpers.sql
2018-04-06 16:34:27,857: Parsing materializations/table.sql
2018-04-06 16:34:27,880: Parsing materializations/archive.sql
2018-04-06 16:34:27,920: Parsing materializations/incremental.sql
2018-04-06 16:34:27,955: Parsing etc/get_custom_schema.sql
2018-04-06 16:34:27,962: Parsing adapters/bigquery.sql
2018-04-06 16:34:27,967: Parsing adapters/common.sql
2018-04-06 16:34:27,993: Parsing adapters/redshift.sql
2018-04-06 16:34:28,016: Parsing adapters/postgres.sql
2018-04-06 16:34:28,020: Parsing schema_tests/relationships.sql
2018-04-06 16:34:28,022: Parsing schema_tests/not_null.sql
2018-04-06 16:34:28,024: Parsing schema_tests/unique.sql
2018-04-06 16:34:28,026: Parsing schema_tests/accepted_values.sql
2018-04-06 16:34:28,035: Parsing model.compology.fl_empty_groups
2018-04-06 16:34:28,037: Parsing model.compology.location_history
2018-04-06 16:34:28,038: Parsing model.compology.post_history
2018-04-06 16:34:28,041: Parsing model.compology.fl_level_at_service
2018-04-06 16:34:28,046: Found 42 macros, 0 analyses, 0 archives, 0 tests, 4 models, 0 operations
2018-04-06 16:34:28,049: 
2018-04-06 16:34:28,052: Acquiring new postgres connection "master".
2018-04-06 16:34:28,052: Opening a new connection (0 currently allocated)
2018-04-06 16:34:28,058: Using postgres connection "master".
2018-04-06 16:34:28,058: On master: select distinct nspname from pg_namespace
2018-04-06 16:34:28,060: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 16:34:28,063: Using postgres connection "master".
2018-04-06 16:34:28,063: On master: BEGIN
2018-04-06 16:34:28,064: SQL status: BEGIN in 0.00 seconds
2018-04-06 16:34:28,064: On master: COMMIT
2018-04-06 16:34:28,064: Using postgres connection "master".
2018-04-06 16:34:28,064: On master: COMMIT
2018-04-06 16:34:28,064: SQL status: COMMIT in 0.00 seconds
2018-04-06 16:34:28,072: 16:34:28 | Concurrency: 1 threads (target='dev')
2018-04-06 16:34:28,072: 16:34:28 | 
2018-04-06 16:34:28,072: Using postgres connection "master".
2018-04-06 16:34:28,072: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 16:34:28,075: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 16:34:28,097: 16:34:28 | 1 of 4 START table model dbt_clarice.location_history................ [RUN]
2018-04-06 16:34:28,097: Compiling model.compology.location_history
2018-04-06 16:34:28,103: Writing injected SQL for node "model.compology.location_history"
2018-04-06 16:34:28,104: Acquiring new postgres connection "location_history".
2018-04-06 16:34:28,104: Opening a new connection (1 currently allocated)
2018-04-06 16:34:28,109: Using postgres connection "location_history".
2018-04-06 16:34:28,109: On location_history: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 16:34:28,114: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 16:34:28,116: Writing runtime SQL for node "model.compology.location_history"
2018-04-06 16:34:28,117: Using postgres connection "location_history".
2018-04-06 16:34:28,117: On location_history: BEGIN
2018-04-06 16:34:28,117: SQL status: BEGIN in 0.00 seconds
2018-04-06 16:34:28,118: Using postgres connection "location_history".
2018-04-06 16:34:28,118: On location_history: 
  
    
  

  
    
  create  table
    "dbt_clarice"."location_history__dbt_tmp" as (
    

select dumpster_id,
location_id,
arrived_at,
lead(arrived_at) over w as "departed_at"
from platform.dumpster_arrival
where is_active
window w as (partition by dumpster_id order by arrived_at asc)
  );
2018-04-06 16:34:33,570: SQL status: SELECT 187799 in 5.45 seconds
2018-04-06 16:34:33,574: Using postgres connection "location_history".
2018-04-06 16:34:33,574: On location_history: drop table if exists "dbt_clarice"."location_history" cascade
2018-04-06 16:34:33,575: SQL status: DROP TABLE in 0.00 seconds
2018-04-06 16:34:33,575: Using postgres connection "location_history".
2018-04-06 16:34:33,575: On location_history: alter table "dbt_clarice"."location_history__dbt_tmp" rename to "location_history"
2018-04-06 16:34:33,578: SQL status: ALTER TABLE in 0.00 seconds
2018-04-06 16:34:33,578: On location_history: COMMIT
2018-04-06 16:34:33,578: Using postgres connection "location_history".
2018-04-06 16:34:33,578: On location_history: COMMIT
2018-04-06 16:34:33,585: SQL status: COMMIT in 0.01 seconds
2018-04-06 16:34:33,586: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3c37d0>], 'label': 'a60aca70-3a99-439c-8008-52617c4ab243'}
2018-04-06 16:34:33,934: 16:34:33 | 1 of 4 OK created table model dbt_clarice.location_history........... [SELECT 187799 in 5.49s]
2018-04-06 16:34:33,934: 16:34:33 | 2 of 4 START table model dbt_clarice.fl_empty_groups................. [RUN]
2018-04-06 16:34:33,935: Compiling model.compology.fl_empty_groups
2018-04-06 16:34:33,941: Writing injected SQL for node "model.compology.fl_empty_groups"
2018-04-06 16:34:33,943: Acquiring new postgres connection "fl_empty_groups".
2018-04-06 16:34:33,943: Re-using an available connection from the pool.
2018-04-06 16:34:33,943: Using postgres connection "fl_empty_groups".
2018-04-06 16:34:33,943: On fl_empty_groups: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 16:34:33,944: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 16:34:33,946: Writing runtime SQL for node "model.compology.fl_empty_groups"
2018-04-06 16:34:33,947: Using postgres connection "fl_empty_groups".
2018-04-06 16:34:33,947: On fl_empty_groups: BEGIN
2018-04-06 16:34:33,947: SQL status: BEGIN in 0.00 seconds
2018-04-06 16:34:33,948: Using postgres connection "fl_empty_groups".
2018-04-06 16:34:33,948: On fl_empty_groups: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_empty_groups__dbt_tmp" as (
    

with empty_groups as (
  select ee.dumpster_id,
  d.organization as "org_id",
  lag(ee.occurred_at) over w as "empty_group_start",
  ee.occurred_at as "empty_group_end",
  ee.end_raw_device_data_id,
  row_number() over w as "empty_group",
  ee.updated_at -- placeholder, may want different logic for this later
  from platform.empty_event ee
  inner join platform.dumpster d
  on ee.dumpster_id = d.id
  where ee.was_emptied
  and ee.confidence > 0.5
  window w as (partition by ee.dumpster_id order by ee.occurred_at asc)
)
select dumpster_id,
org_id,
empty_group_start,
empty_group_end,
end_raw_device_data_id,
dumpster_id || '_eg' || empty_group::text as "empty_group_id",
updated_at
from empty_groups
order by 6 desc
  );
2018-04-06 16:34:43,554: SQL status: SELECT 215895 in 9.61 seconds
2018-04-06 16:34:43,555: Using postgres connection "fl_empty_groups".
2018-04-06 16:34:43,556: On fl_empty_groups: drop table if exists "dbt_clarice"."fl_empty_groups" cascade
2018-04-06 16:34:43,557: SQL status: DROP TABLE in 0.00 seconds
2018-04-06 16:34:43,557: Using postgres connection "fl_empty_groups".
2018-04-06 16:34:43,557: On fl_empty_groups: alter table "dbt_clarice"."fl_empty_groups__dbt_tmp" rename to "fl_empty_groups"
2018-04-06 16:34:43,567: SQL status: ALTER TABLE in 0.01 seconds
2018-04-06 16:34:43,567: On fl_empty_groups: COMMIT
2018-04-06 16:34:43,567: Using postgres connection "fl_empty_groups".
2018-04-06 16:34:43,568: On fl_empty_groups: COMMIT
2018-04-06 16:34:43,573: SQL status: COMMIT in 0.01 seconds
2018-04-06 16:34:43,573: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3c37d0>], 'label': 'a60aca70-3a99-439c-8008-52617c4ab243'}
2018-04-06 16:34:43,919: 16:34:43 | 2 of 4 OK created table model dbt_clarice.fl_empty_groups............ [SELECT 215895 in 9.64s]
2018-04-06 16:34:43,919: 16:34:43 | 3 of 4 START table model dbt_clarice.post_history.................... [RUN]
2018-04-06 16:34:43,920: Compiling model.compology.post_history
2018-04-06 16:34:43,925: Writing injected SQL for node "model.compology.post_history"
2018-04-06 16:34:43,927: Acquiring new postgres connection "post_history".
2018-04-06 16:34:43,927: Re-using an available connection from the pool.
2018-04-06 16:34:43,927: Using postgres connection "post_history".
2018-04-06 16:34:43,927: On post_history: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 16:34:43,928: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 16:34:43,932: Writing runtime SQL for node "model.compology.post_history"
2018-04-06 16:34:43,933: Using postgres connection "post_history".
2018-04-06 16:34:43,933: On post_history: BEGIN
2018-04-06 16:34:43,933: SQL status: BEGIN in 0.00 seconds
2018-04-06 16:34:43,933: Using postgres connection "post_history".
2018-04-06 16:34:43,933: On post_history: 
  
    
  

  
    
  create  table
    "dbt_clarice"."post_history__dbt_tmp" as (
    

select rdd.id as "raw_device_data_id",
d.organization as "org_id",
rdd.dumpster_id,
d.container_type,
d.dumpster_timezone,
rdd.post_timestamp,
rdd.agg_camera_blocked,
rdd.agg_level,
l.id as "location_id",
l.description as "location_name",
l.type as "location_type",
da.is_active,
rdd.lat,
rdd.lon,
case when rdd.latlon_radius in (0, 70000) then null else rdd.latlon_radius end as "latlon_radius",
case when rdd.latlon_radius < 50 and rdd.latlon_radius != 0 then 1 else 0 end as "good_gps",
firmware,
case
  when firmware like 'oscar-00%' or firmware = 'oscar-lte2' then 'R10'
  when firmware like 'oscar-_1%' then 'R11'
  when firmware like 'oscar-_2%' then 'R12'
  else null end as "sensor_model",
case
  when (rdd.extra_info::json ->> 'wake_reason') = '0' then 'unknown'
  when (rdd.extra_info::json ->> 'wake_reason') = '1' then 'scheduled post'
  when (rdd.extra_info::json ->> 'wake_reason') = '2' then 'accelerometer trigger'
  when (rdd.extra_info::json ->> 'wake_reason') = '3' then 'FW/HW issue'
  when (rdd.extra_info::json ->> 'wake_reason') = '4' then 'power issue'
  when (rdd.extra_info::json ->> 'wake_reason') = '5' then 'reset after programming'
  else null end as "wake_reason",
case
  when rdd.extra_info::json ->> 'accel_int' is null then null
  when rdd.extra_info::json ->> 'accel_int' = 'true' then true
  else false end as "accel_int",
(rdd.extra_info::json ->> 'signal_dbi')::int as "signal_dbi",
(rdd.extra_info::json ->> 'consecutive_failed_wakes')::int as "consecutive_failed_wakes",
(rdd.extra_info::json ->> 'session_count')::int as "session_count",
rdd.errors::text as "errors"
from platform.raw_device_data rdd
inner join platform.dumpster d
on rdd.dumpster_id = d.id
left join platform.dumpster_arrival da
on rdd.id = da.raw_device_data_id
left join platform.location l
on da.location_id = l.id
where not d.is_hidden
and not d.is_hidden_for_org
and not rdd.in_maintenance_mode
  );
2018-04-06 16:41:59,649: SQL status: SELECT 5429233 in 435.72 seconds
2018-04-06 16:41:59,650: Using postgres connection "post_history".
2018-04-06 16:41:59,651: On post_history: drop table if exists "dbt_clarice"."post_history" cascade
2018-04-06 16:41:59,652: SQL status: DROP TABLE in 0.00 seconds
2018-04-06 16:41:59,652: Using postgres connection "post_history".
2018-04-06 16:41:59,652: On post_history: alter table "dbt_clarice"."post_history__dbt_tmp" rename to "post_history"
2018-04-06 16:41:59,653: SQL status: ALTER TABLE in 0.00 seconds
2018-04-06 16:41:59,653: On post_history: COMMIT
2018-04-06 16:41:59,653: Using postgres connection "post_history".
2018-04-06 16:41:59,653: On post_history: COMMIT
2018-04-06 16:41:59,663: SQL status: COMMIT in 0.01 seconds
2018-04-06 16:41:59,663: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2d9410>], 'label': 'a60aca70-3a99-439c-8008-52617c4ab243'}
2018-04-06 16:42:00,042: 16:42:00 | 3 of 4 OK created table model dbt_clarice.post_history............... [SELECT 5429233 in 435.74s]
2018-04-06 16:42:00,043: 16:42:00 | 4 of 4 START table model dbt_clarice.fl_level_at_service............. [RUN]
2018-04-06 16:42:00,043: Compiling model.compology.fl_level_at_service
2018-04-06 16:42:00,051: Writing injected SQL for node "model.compology.fl_level_at_service"
2018-04-06 16:42:00,054: Acquiring new postgres connection "fl_level_at_service".
2018-04-06 16:42:00,055: Re-using an available connection from the pool.
2018-04-06 16:42:00,055: Using postgres connection "fl_level_at_service".
2018-04-06 16:42:00,055: On fl_level_at_service: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 16:42:00,056: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 16:42:00,060: Writing runtime SQL for node "model.compology.fl_level_at_service"
2018-04-06 16:42:00,062: Using postgres connection "fl_level_at_service".
2018-04-06 16:42:00,062: On fl_level_at_service: BEGIN
2018-04-06 16:42:00,063: SQL status: BEGIN in 0.00 seconds
2018-04-06 16:42:00,063: Using postgres connection "fl_level_at_service".
2018-04-06 16:42:00,063: On fl_level_at_service: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_level_at_service__dbt_tmp" as (
    

with no_camera_blocked as (
  select dumpster_id, org_id, post_timestamp, agg_level
  from "dbt_clarice"."post_history"
  where container_type = 'front load'
  and agg_level is not null
), empty_groups as (
  select *
  from "dbt_clarice"."fl_empty_groups"
  where empty_group_end is not null
), posts_with_empty_groups as (
  select ncb.*,
  lag(ncb.agg_level) over (partition by ncb.dumpster_id, eg.empty_group order by ncb.post_timestamp asc) as "lag_level",
  eg.empty_group
  from post_history ph
  left join empty_groups eg
  on (ncb.dumpster_id = eg.dumpster_id
    and ncb.post_timestamp > eg.empty_group_start
    and ncb.post_timestamp <= eg.empty_group_end)
  where eg.empty_group_end is not null
), max_level as (
  select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
  peg.empty_group,
  max(peg.agg_level) over (partition by peg.dumpster_id, peg.empty_group) as "max_level"
  from posts_with_empty_groups peg
  order by peg.dumpster_id, peg.empty_group
)
select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
peg.org_id,
peg.empty_group,
peg.post_timestamp,
peg.raw_device_data_id,
peg.agg_level as "level_at_service",
peg.lag_level as "level_prior_to_service",
ml.max_level as "max_level_before_service"
from posts_with_empty_groups peg
left join max_level ml
on (peg.dumpster_id = ml.dumpster_id and peg.empty_group = ml.empty_group)
order by peg.dumpster_id, peg.empty_group, peg.post_timestamp desc
  );
2018-04-06 16:42:00,065: Postgres error: relation "post_history" does not exist
LINE 25:   from post_history ph
                ^

2018-04-06 16:42:00,065: On fl_level_at_service: ROLLBACK
2018-04-06 16:42:00,066: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3c3dd0>], 'label': 'a60aca70-3a99-439c-8008-52617c4ab243'}
2018-04-06 16:42:00,405: 16:42:00 | 4 of 4 ERROR creating table model dbt_clarice.fl_level_at_service.... [ERROR in 0.02s]
2018-04-06 16:42:00,502: Using postgres connection "master".
2018-04-06 16:42:00,503: On master: BEGIN
2018-04-06 16:42:00,503: SQL status: BEGIN in 0.00 seconds
2018-04-06 16:42:00,504: On master: COMMIT
2018-04-06 16:42:00,504: Using postgres connection "master".
2018-04-06 16:42:00,504: On master: COMMIT
2018-04-06 16:42:00,504: SQL status: COMMIT in 0.00 seconds
2018-04-06 16:42:00,504: 16:42:00 | 
2018-04-06 16:42:00,505: 16:42:00 | Finished running 4 table models in 452.45s.
2018-04-06 16:42:00,505: Connection 'master' was left open.
2018-04-06 16:42:00,505: 
2018-04-06 16:42:00,505: Completed with 1 errors:
2018-04-06 16:42:00,505: 
2018-04-06 16:42:00,506: Database Error in model fl_level_at_service (models/fl_level_at_service.sql)
2018-04-06 16:42:00,506:   relation "post_history" does not exist
2018-04-06 16:42:00,506:   LINE 25:   from post_history ph
2018-04-06 16:42:00,507:                   ^
2018-04-06 16:42:00,507:   compiled SQL at target/run/compology/fl_level_at_service.sql
2018-04-06 16:42:00,507: 
Done. PASS=3 ERROR=1 SKIP=0 TOTAL=4
2018-04-06 16:42:00,508: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c306710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da362d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f398790>], 'label': 'end'}
2018-04-06 16:42:00,914: Flushing usage events
2018-04-06 16:50:57,918: Tracking: tracking
2018-04-06 16:50:57,919: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10793ab10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10793aa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10793ad50>], 'label': 'start'}
2018-04-06 16:50:58,350: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 16:50:58,369: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 16:50:58,371: Parsing core.sql
2018-04-06 16:50:58,387: Parsing materializations/view.sql
2018-04-06 16:50:58,406: Parsing materializations/bigquery.sql
2018-04-06 16:50:58,424: Parsing materializations/wrapper.sql
2018-04-06 16:50:58,428: Parsing materializations/helpers.sql
2018-04-06 16:50:58,451: Parsing materializations/table.sql
2018-04-06 16:50:58,474: Parsing materializations/archive.sql
2018-04-06 16:50:58,516: Parsing materializations/incremental.sql
2018-04-06 16:50:58,551: Parsing etc/get_custom_schema.sql
2018-04-06 16:50:58,557: Parsing adapters/bigquery.sql
2018-04-06 16:50:58,564: Parsing adapters/common.sql
2018-04-06 16:50:58,591: Parsing adapters/redshift.sql
2018-04-06 16:50:58,620: Parsing adapters/postgres.sql
2018-04-06 16:50:58,624: Parsing schema_tests/relationships.sql
2018-04-06 16:50:58,627: Parsing schema_tests/not_null.sql
2018-04-06 16:50:58,630: Parsing schema_tests/unique.sql
2018-04-06 16:50:58,633: Parsing schema_tests/accepted_values.sql
2018-04-06 16:50:58,641: Parsing model.compology.fl_empty_groups
2018-04-06 16:50:58,644: Parsing model.compology.location_history
2018-04-06 16:50:58,648: Parsing model.compology.post_history
2018-04-06 16:50:58,650: Parsing model.compology.fl_level_at_service
2018-04-06 16:50:58,655: Found 42 macros, 0 analyses, 0 archives, 0 tests, 4 models, 0 operations
2018-04-06 16:50:58,659: 
2018-04-06 16:50:58,662: Acquiring new postgres connection "master".
2018-04-06 16:50:58,662: Opening a new connection (0 currently allocated)
2018-04-06 16:50:58,668: Using postgres connection "master".
2018-04-06 16:50:58,669: On master: select distinct nspname from pg_namespace
2018-04-06 16:50:58,670: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 16:50:58,673: Using postgres connection "master".
2018-04-06 16:50:58,673: On master: BEGIN
2018-04-06 16:50:58,674: SQL status: BEGIN in 0.00 seconds
2018-04-06 16:50:58,674: On master: COMMIT
2018-04-06 16:50:58,674: Using postgres connection "master".
2018-04-06 16:50:58,674: On master: COMMIT
2018-04-06 16:50:58,675: SQL status: COMMIT in 0.00 seconds
2018-04-06 16:50:58,680: 16:50:58 | Concurrency: 1 threads (target='dev')
2018-04-06 16:50:58,681: 16:50:58 | 
2018-04-06 16:50:58,681: Using postgres connection "master".
2018-04-06 16:50:58,681: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 16:50:58,684: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 16:50:58,689: 16:50:58 | 1 of 1 START table model dbt_clarice.fl_level_at_service............. [RUN]
2018-04-06 16:50:58,689: Compiling model.compology.fl_level_at_service
2018-04-06 16:50:58,699: Writing injected SQL for node "model.compology.fl_level_at_service"
2018-04-06 16:50:58,701: Acquiring new postgres connection "fl_level_at_service".
2018-04-06 16:50:58,701: Opening a new connection (1 currently allocated)
2018-04-06 16:50:58,706: Using postgres connection "fl_level_at_service".
2018-04-06 16:50:58,706: On fl_level_at_service: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 16:50:58,710: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 16:50:58,713: Writing runtime SQL for node "model.compology.fl_level_at_service"
2018-04-06 16:50:58,715: Using postgres connection "fl_level_at_service".
2018-04-06 16:50:58,715: On fl_level_at_service: BEGIN
2018-04-06 16:50:58,716: SQL status: BEGIN in 0.00 seconds
2018-04-06 16:50:58,716: Using postgres connection "fl_level_at_service".
2018-04-06 16:50:58,716: On fl_level_at_service: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_level_at_service__dbt_tmp" as (
    

with no_camera_blocked as (
  select dumpster_id, org_id, post_timestamp, agg_level
  from "dbt_clarice"."post_history"
  where container_type = 'front load'
  and agg_level is not null
), empty_groups as (
  select *
  from "dbt_clarice"."fl_empty_groups"
  where empty_group_end is not null
), posts_with_empty_groups as (
  select ncb.*,
  lag(ncb.agg_level) over (partition by ncb.dumpster_id, eg.empty_group order by ncb.post_timestamp asc) as "lag_level",
  eg.empty_group
  from post_history ph
  left join empty_groups eg
  on (ncb.dumpster_id = eg.dumpster_id
    and ncb.post_timestamp > eg.empty_group_start
    and ncb.post_timestamp <= eg.empty_group_end)
  where eg.empty_group_end is not null
), max_level as (
  select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
  peg.empty_group,
  max(peg.agg_level) over (partition by peg.dumpster_id, peg.empty_group) as "max_level"
  from posts_with_empty_groups peg
  order by peg.dumpster_id, peg.empty_group
)
select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
peg.org_id,
peg.empty_group,
peg.post_timestamp,
peg.raw_device_data_id,
peg.agg_level as "level_at_service",
peg.lag_level as "level_prior_to_service",
ml.max_level as "max_level_before_service"
from posts_with_empty_groups peg
left join max_level ml
on (peg.dumpster_id = ml.dumpster_id and peg.empty_group = ml.empty_group)
order by peg.dumpster_id, peg.empty_group, peg.post_timestamp desc
  );
2018-04-06 16:50:58,717: Postgres error: relation "post_history" does not exist
LINE 25:   from post_history ph
                ^

2018-04-06 16:50:58,717: On fl_level_at_service: ROLLBACK
2018-04-06 16:50:58,717: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a03e10>], 'label': '82b122b2-d0ed-4827-9bf9-faebd06d70ad'}
2018-04-06 16:50:59,048: 16:50:59 | 1 of 1 ERROR creating table model dbt_clarice.fl_level_at_service.... [ERROR in 0.03s]
2018-04-06 16:50:59,102: Using postgres connection "master".
2018-04-06 16:50:59,102: On master: BEGIN
2018-04-06 16:50:59,102: SQL status: BEGIN in 0.00 seconds
2018-04-06 16:50:59,103: On master: COMMIT
2018-04-06 16:50:59,103: Using postgres connection "master".
2018-04-06 16:50:59,103: On master: COMMIT
2018-04-06 16:50:59,103: SQL status: COMMIT in 0.00 seconds
2018-04-06 16:50:59,103: 16:50:59 | 
2018-04-06 16:50:59,104: 16:50:59 | Finished running 1 table models in 0.44s.
2018-04-06 16:50:59,104: Connection 'master' was left open.
2018-04-06 16:50:59,104: 
2018-04-06 16:50:59,105: Completed with 1 errors:
2018-04-06 16:50:59,105: 
2018-04-06 16:50:59,105: Database Error in model fl_level_at_service (models/fl_level_at_service.sql)
2018-04-06 16:50:59,106:   relation "post_history" does not exist
2018-04-06 16:50:59,106:   LINE 25:   from post_history ph
2018-04-06 16:50:59,106:                   ^
2018-04-06 16:50:59,107:   compiled SQL at target/run/compology/fl_level_at_service.sql
2018-04-06 16:50:59,107: 
Done. PASS=0 ERROR=1 SKIP=0 TOTAL=1
2018-04-06 16:50:59,108: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104967710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060972d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a69dd0>], 'label': 'end'}
2018-04-06 16:50:59,442: Flushing usage events
2018-04-06 16:51:58,920: Tracking: tracking
2018-04-06 16:51:58,920: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069adb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069ada10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069add50>], 'label': 'start'}
2018-04-06 16:51:59,297: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 16:51:59,311: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 16:51:59,313: Parsing core.sql
2018-04-06 16:51:59,326: Parsing materializations/view.sql
2018-04-06 16:51:59,344: Parsing materializations/bigquery.sql
2018-04-06 16:51:59,361: Parsing materializations/wrapper.sql
2018-04-06 16:51:59,365: Parsing materializations/helpers.sql
2018-04-06 16:51:59,386: Parsing materializations/table.sql
2018-04-06 16:51:59,409: Parsing materializations/archive.sql
2018-04-06 16:51:59,446: Parsing materializations/incremental.sql
2018-04-06 16:51:59,477: Parsing etc/get_custom_schema.sql
2018-04-06 16:51:59,483: Parsing adapters/bigquery.sql
2018-04-06 16:51:59,489: Parsing adapters/common.sql
2018-04-06 16:51:59,516: Parsing adapters/redshift.sql
2018-04-06 16:51:59,541: Parsing adapters/postgres.sql
2018-04-06 16:51:59,545: Parsing schema_tests/relationships.sql
2018-04-06 16:51:59,549: Parsing schema_tests/not_null.sql
2018-04-06 16:51:59,552: Parsing schema_tests/unique.sql
2018-04-06 16:51:59,554: Parsing schema_tests/accepted_values.sql
2018-04-06 16:51:59,563: Parsing model.compology.fl_empty_groups
2018-04-06 16:51:59,566: Parsing model.compology.location_history
2018-04-06 16:51:59,570: Parsing model.compology.post_history
2018-04-06 16:51:59,573: Parsing model.compology.fl_level_at_service
2018-04-06 16:51:59,580: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106adcdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a1e790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a1e9d0>], 'label': 'end'}
2018-04-06 16:51:59,916: Encountered an error:
2018-04-06 16:51:59,916: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'post_history.sql' which was not found or is disabled
2018-04-06 16:51:59,927: Traceback (most recent call last):
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/anaconda2/lib/python2.7/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 223, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 183, in run_from_graph
    flat_graph, linker = self.compile(self.project)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 179, in compile
    (flat_graph, linker) = compiler.compile()
  File "/anaconda2/lib/python2.7/site-packages/dbt/compilation.py", line 281, in compile
    root_project.get('name'))
  File "/anaconda2/lib/python2.7/site-packages/dbt/parser.py", line 100, in process_refs
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/utils.py", line 377, in invalid_ref_fail_unless_test
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 165, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 116, in raise_compiler_error
    raise CompilationException(msg, node)
CompilationException: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'post_history.sql' which was not found or is disabled

2018-04-06 16:54:23,811: Tracking: tracking
2018-04-06 16:54:23,812: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150bd57b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150bd57a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150bd57d50>], 'label': 'start'}
2018-04-06 16:54:24,189: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 16:54:24,206: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 16:54:24,209: Parsing core.sql
2018-04-06 16:54:24,230: Parsing materializations/view.sql
2018-04-06 16:54:24,251: Parsing materializations/bigquery.sql
2018-04-06 16:54:24,271: Parsing materializations/wrapper.sql
2018-04-06 16:54:24,277: Parsing materializations/helpers.sql
2018-04-06 16:54:24,309: Parsing materializations/table.sql
2018-04-06 16:54:24,335: Parsing materializations/archive.sql
2018-04-06 16:54:24,382: Parsing materializations/incremental.sql
2018-04-06 16:54:24,423: Parsing etc/get_custom_schema.sql
2018-04-06 16:54:24,432: Parsing adapters/bigquery.sql
2018-04-06 16:54:24,438: Parsing adapters/common.sql
2018-04-06 16:54:24,465: Parsing adapters/redshift.sql
2018-04-06 16:54:24,492: Parsing adapters/postgres.sql
2018-04-06 16:54:24,496: Parsing schema_tests/relationships.sql
2018-04-06 16:54:24,498: Parsing schema_tests/not_null.sql
2018-04-06 16:54:24,500: Parsing schema_tests/unique.sql
2018-04-06 16:54:24,503: Parsing schema_tests/accepted_values.sql
2018-04-06 16:54:24,515: Parsing model.compology.fl_empty_groups
2018-04-06 16:54:24,517: Parsing model.compology.location_history
2018-04-06 16:54:24,520: Parsing model.compology.post_history
2018-04-06 16:54:24,522: Parsing model.compology.fl_level_at_service
2018-04-06 16:54:24,527: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150be86dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150bdc8790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150bdc89d0>], 'label': 'end'}
2018-04-06 16:54:24,862: Encountered an error:
2018-04-06 16:54:24,862: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'post_history.sql' which was not found or is disabled
2018-04-06 16:54:24,867: Traceback (most recent call last):
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/anaconda2/lib/python2.7/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 223, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 183, in run_from_graph
    flat_graph, linker = self.compile(self.project)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 179, in compile
    (flat_graph, linker) = compiler.compile()
  File "/anaconda2/lib/python2.7/site-packages/dbt/compilation.py", line 281, in compile
    root_project.get('name'))
  File "/anaconda2/lib/python2.7/site-packages/dbt/parser.py", line 100, in process_refs
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/utils.py", line 377, in invalid_ref_fail_unless_test
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 165, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 116, in raise_compiler_error
    raise CompilationException(msg, node)
CompilationException: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'post_history.sql' which was not found or is disabled

2018-04-06 16:59:07,934: Tracking: tracking
2018-04-06 16:59:07,935: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1509467b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1509467a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1509467d50>], 'label': 'start'}
2018-04-06 16:59:08,367: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 16:59:08,385: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 16:59:08,387: Parsing core.sql
2018-04-06 16:59:08,401: Parsing materializations/view.sql
2018-04-06 16:59:08,420: Parsing materializations/bigquery.sql
2018-04-06 16:59:08,435: Parsing materializations/wrapper.sql
2018-04-06 16:59:08,440: Parsing materializations/helpers.sql
2018-04-06 16:59:08,461: Parsing materializations/table.sql
2018-04-06 16:59:08,482: Parsing materializations/archive.sql
2018-04-06 16:59:08,518: Parsing materializations/incremental.sql
2018-04-06 16:59:08,550: Parsing etc/get_custom_schema.sql
2018-04-06 16:59:08,556: Parsing adapters/bigquery.sql
2018-04-06 16:59:08,562: Parsing adapters/common.sql
2018-04-06 16:59:08,585: Parsing adapters/redshift.sql
2018-04-06 16:59:08,608: Parsing adapters/postgres.sql
2018-04-06 16:59:08,612: Parsing schema_tests/relationships.sql
2018-04-06 16:59:08,616: Parsing schema_tests/not_null.sql
2018-04-06 16:59:08,618: Parsing schema_tests/unique.sql
2018-04-06 16:59:08,620: Parsing schema_tests/accepted_values.sql
2018-04-06 16:59:08,627: Parsing model.compology.fl_empty_groups
2018-04-06 16:59:08,629: Parsing model.compology.location_history
2018-04-06 16:59:08,631: Parsing model.compology.post_history
2018-04-06 16:59:08,633: Parsing model.compology.fl_level_at_service
2018-04-06 16:59:08,638: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1509596dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15094d8790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15094d89d0>], 'label': 'end'}
2018-04-06 16:59:08,971: Encountered an error:
2018-04-06 16:59:08,972: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'models/post_history.sql' which was not found or is disabled
2018-04-06 16:59:08,977: Traceback (most recent call last):
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/anaconda2/lib/python2.7/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 223, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 183, in run_from_graph
    flat_graph, linker = self.compile(self.project)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 179, in compile
    (flat_graph, linker) = compiler.compile()
  File "/anaconda2/lib/python2.7/site-packages/dbt/compilation.py", line 281, in compile
    root_project.get('name'))
  File "/anaconda2/lib/python2.7/site-packages/dbt/parser.py", line 100, in process_refs
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/utils.py", line 377, in invalid_ref_fail_unless_test
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 165, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 116, in raise_compiler_error
    raise CompilationException(msg, node)
CompilationException: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'models/post_history.sql' which was not found or is disabled

2018-04-06 16:59:40,565: Tracking: tracking
2018-04-06 16:59:40,566: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee6eb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee6ea10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee6ed50>], 'label': 'start'}
2018-04-06 16:59:40,943: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 16:59:40,957: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 16:59:40,958: Parsing core.sql
2018-04-06 16:59:40,974: Parsing materializations/view.sql
2018-04-06 16:59:40,992: Parsing materializations/bigquery.sql
2018-04-06 16:59:41,008: Parsing materializations/wrapper.sql
2018-04-06 16:59:41,012: Parsing materializations/helpers.sql
2018-04-06 16:59:41,031: Parsing materializations/table.sql
2018-04-06 16:59:41,052: Parsing materializations/archive.sql
2018-04-06 16:59:41,087: Parsing materializations/incremental.sql
2018-04-06 16:59:41,119: Parsing etc/get_custom_schema.sql
2018-04-06 16:59:41,125: Parsing adapters/bigquery.sql
2018-04-06 16:59:41,131: Parsing adapters/common.sql
2018-04-06 16:59:41,156: Parsing adapters/redshift.sql
2018-04-06 16:59:41,178: Parsing adapters/postgres.sql
2018-04-06 16:59:41,182: Parsing schema_tests/relationships.sql
2018-04-06 16:59:41,184: Parsing schema_tests/not_null.sql
2018-04-06 16:59:41,186: Parsing schema_tests/unique.sql
2018-04-06 16:59:41,188: Parsing schema_tests/accepted_values.sql
2018-04-06 16:59:41,195: Parsing model.compology.fl_empty_groups
2018-04-06 16:59:41,197: Parsing model.compology.location_history
2018-04-06 16:59:41,199: Parsing model.compology.post_history
2018-04-06 16:59:41,201: Parsing model.compology.fl_level_at_service
2018-04-06 16:59:41,206: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef9ddd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eedf790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eedf9d0>], 'label': 'end'}
2018-04-06 16:59:41,542: Encountered an error:
2018-04-06 16:59:41,542: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'compology/models/post_history.sql' which was not found or is disabled
2018-04-06 16:59:41,543: Traceback (most recent call last):
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/anaconda2/lib/python2.7/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 223, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 183, in run_from_graph
    flat_graph, linker = self.compile(self.project)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 179, in compile
    (flat_graph, linker) = compiler.compile()
  File "/anaconda2/lib/python2.7/site-packages/dbt/compilation.py", line 281, in compile
    root_project.get('name'))
  File "/anaconda2/lib/python2.7/site-packages/dbt/parser.py", line 100, in process_refs
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/utils.py", line 377, in invalid_ref_fail_unless_test
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 165, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 116, in raise_compiler_error
    raise CompilationException(msg, node)
CompilationException: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'compology/models/post_history.sql' which was not found or is disabled

2018-04-06 16:59:47,528: Tracking: tracking
2018-04-06 16:59:47,528: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fd3b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fd3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fd3d50>], 'label': 'start'}
2018-04-06 16:59:47,882: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 16:59:47,896: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 16:59:47,898: Parsing core.sql
2018-04-06 16:59:47,913: Parsing materializations/view.sql
2018-04-06 16:59:47,931: Parsing materializations/bigquery.sql
2018-04-06 16:59:47,948: Parsing materializations/wrapper.sql
2018-04-06 16:59:47,952: Parsing materializations/helpers.sql
2018-04-06 16:59:47,973: Parsing materializations/table.sql
2018-04-06 16:59:47,993: Parsing materializations/archive.sql
2018-04-06 16:59:48,028: Parsing materializations/incremental.sql
2018-04-06 16:59:48,057: Parsing etc/get_custom_schema.sql
2018-04-06 16:59:48,063: Parsing adapters/bigquery.sql
2018-04-06 16:59:48,069: Parsing adapters/common.sql
2018-04-06 16:59:48,091: Parsing adapters/redshift.sql
2018-04-06 16:59:48,115: Parsing adapters/postgres.sql
2018-04-06 16:59:48,118: Parsing schema_tests/relationships.sql
2018-04-06 16:59:48,121: Parsing schema_tests/not_null.sql
2018-04-06 16:59:48,122: Parsing schema_tests/unique.sql
2018-04-06 16:59:48,124: Parsing schema_tests/accepted_values.sql
2018-04-06 16:59:48,133: Parsing model.compology.fl_empty_groups
2018-04-06 16:59:48,136: Parsing model.compology.location_history
2018-04-06 16:59:48,138: Parsing model.compology.post_history
2018-04-06 16:59:48,140: Parsing model.compology.fl_level_at_service
2018-04-06 16:59:48,144: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140bcdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114043790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140439d0>], 'label': 'end'}
2018-04-06 16:59:48,864: Encountered an error:
2018-04-06 16:59:48,865: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'compology/models/post_history.sql' which was not found or is disabled
2018-04-06 16:59:48,868: Traceback (most recent call last):
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/anaconda2/lib/python2.7/site-packages/dbt/task/compile.py", line 25, in run
    results = runner.run(query, CompileRunner)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 223, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 183, in run_from_graph
    flat_graph, linker = self.compile(self.project)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 179, in compile
    (flat_graph, linker) = compiler.compile()
  File "/anaconda2/lib/python2.7/site-packages/dbt/compilation.py", line 281, in compile
    root_project.get('name'))
  File "/anaconda2/lib/python2.7/site-packages/dbt/parser.py", line 100, in process_refs
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/utils.py", line 377, in invalid_ref_fail_unless_test
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 165, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 116, in raise_compiler_error
    raise CompilationException(msg, node)
CompilationException: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'compology/models/post_history.sql' which was not found or is disabled

2018-04-06 17:00:14,189: Tracking: tracking
2018-04-06 17:00:14,190: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150b6a4b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150b6a4a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150b6a4d50>], 'label': 'start'}
2018-04-06 17:00:14,537: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 17:00:14,559: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 17:00:14,561: Parsing core.sql
2018-04-06 17:00:14,579: Parsing materializations/view.sql
2018-04-06 17:00:14,597: Parsing materializations/bigquery.sql
2018-04-06 17:00:14,613: Parsing materializations/wrapper.sql
2018-04-06 17:00:14,617: Parsing materializations/helpers.sql
2018-04-06 17:00:14,637: Parsing materializations/table.sql
2018-04-06 17:00:14,659: Parsing materializations/archive.sql
2018-04-06 17:00:14,694: Parsing materializations/incremental.sql
2018-04-06 17:00:14,724: Parsing etc/get_custom_schema.sql
2018-04-06 17:00:14,730: Parsing adapters/bigquery.sql
2018-04-06 17:00:14,736: Parsing adapters/common.sql
2018-04-06 17:00:14,763: Parsing adapters/redshift.sql
2018-04-06 17:00:14,792: Parsing adapters/postgres.sql
2018-04-06 17:00:14,796: Parsing schema_tests/relationships.sql
2018-04-06 17:00:14,800: Parsing schema_tests/not_null.sql
2018-04-06 17:00:14,802: Parsing schema_tests/unique.sql
2018-04-06 17:00:14,805: Parsing schema_tests/accepted_values.sql
2018-04-06 17:00:14,814: Parsing model.compology.fl_empty_groups
2018-04-06 17:00:14,816: Parsing model.compology.location_history
2018-04-06 17:00:14,819: Parsing model.compology.post_history
2018-04-06 17:00:14,821: Parsing model.compology.fl_level_at_service
2018-04-06 17:00:14,827: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150b7d3dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150b715790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150b7159d0>], 'label': 'end'}
2018-04-06 17:00:15,193: Encountered an error:
2018-04-06 17:00:15,193: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'dbt_local/compology/models/post_history.sql' which was not found or is disabled
2018-04-06 17:00:15,194: Traceback (most recent call last):
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/anaconda2/lib/python2.7/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 223, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 183, in run_from_graph
    flat_graph, linker = self.compile(self.project)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 179, in compile
    (flat_graph, linker) = compiler.compile()
  File "/anaconda2/lib/python2.7/site-packages/dbt/compilation.py", line 281, in compile
    root_project.get('name'))
  File "/anaconda2/lib/python2.7/site-packages/dbt/parser.py", line 100, in process_refs
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/utils.py", line 377, in invalid_ref_fail_unless_test
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 165, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 116, in raise_compiler_error
    raise CompilationException(msg, node)
CompilationException: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'dbt_local/compology/models/post_history.sql' which was not found or is disabled

2018-04-06 17:09:10,233: Tracking: tracking
2018-04-06 17:09:10,234: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac43b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac43a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac43d50>], 'label': 'start'}
2018-04-06 17:09:10,679: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 17:09:10,697: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 17:09:10,699: Parsing core.sql
2018-04-06 17:09:10,713: Parsing materializations/view.sql
2018-04-06 17:09:10,730: Parsing materializations/bigquery.sql
2018-04-06 17:09:10,744: Parsing materializations/wrapper.sql
2018-04-06 17:09:10,748: Parsing materializations/helpers.sql
2018-04-06 17:09:10,768: Parsing materializations/table.sql
2018-04-06 17:09:10,789: Parsing materializations/archive.sql
2018-04-06 17:09:10,824: Parsing materializations/incremental.sql
2018-04-06 17:09:10,854: Parsing etc/get_custom_schema.sql
2018-04-06 17:09:10,861: Parsing adapters/bigquery.sql
2018-04-06 17:09:10,866: Parsing adapters/common.sql
2018-04-06 17:09:10,889: Parsing adapters/redshift.sql
2018-04-06 17:09:10,911: Parsing adapters/postgres.sql
2018-04-06 17:09:10,915: Parsing schema_tests/relationships.sql
2018-04-06 17:09:10,918: Parsing schema_tests/not_null.sql
2018-04-06 17:09:10,920: Parsing schema_tests/unique.sql
2018-04-06 17:09:10,923: Parsing schema_tests/accepted_values.sql
2018-04-06 17:09:10,929: Parsing model.compology.fl_empty_groups
2018-04-06 17:09:10,931: Parsing model.compology.location_history
2018-04-06 17:09:10,933: Parsing model.compology.post_history
2018-04-06 17:09:10,936: Parsing model.compology.fl_level_at_service
2018-04-06 17:09:10,940: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad72dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acb4790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acb49d0>], 'label': 'end'}
2018-04-06 17:09:11,269: Encountered an error:
2018-04-06 17:09:11,270: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'post_history.sql' which was not found or is disabled
2018-04-06 17:09:11,281: Traceback (most recent call last):
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/anaconda2/lib/python2.7/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/anaconda2/lib/python2.7/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 223, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 183, in run_from_graph
    flat_graph, linker = self.compile(self.project)
  File "/anaconda2/lib/python2.7/site-packages/dbt/runner.py", line 179, in compile
    (flat_graph, linker) = compiler.compile()
  File "/anaconda2/lib/python2.7/site-packages/dbt/compilation.py", line 281, in compile
    root_project.get('name'))
  File "/anaconda2/lib/python2.7/site-packages/dbt/parser.py", line 100, in process_refs
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/utils.py", line 377, in invalid_ref_fail_unless_test
    target_model_package)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 165, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/anaconda2/lib/python2.7/site-packages/dbt/exceptions.py", line 116, in raise_compiler_error
    raise CompilationException(msg, node)
CompilationException: Compilation Error in model fl_level_at_service (models/fl_level_at_service.sql)
  Model 'model.compology.fl_level_at_service' depends on model 'post_history.sql' which was not found or is disabled

2018-04-06 17:09:44,434: Tracking: tracking
2018-04-06 17:09:44,435: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1508a5cb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1508a5ca10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1508a5cd50>], 'label': 'start'}
2018-04-06 17:09:44,781: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 17:09:44,797: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 17:09:44,799: Parsing core.sql
2018-04-06 17:09:44,811: Parsing materializations/view.sql
2018-04-06 17:09:44,828: Parsing materializations/bigquery.sql
2018-04-06 17:09:44,842: Parsing materializations/wrapper.sql
2018-04-06 17:09:44,846: Parsing materializations/helpers.sql
2018-04-06 17:09:44,865: Parsing materializations/table.sql
2018-04-06 17:09:44,886: Parsing materializations/archive.sql
2018-04-06 17:09:44,920: Parsing materializations/incremental.sql
2018-04-06 17:09:44,949: Parsing etc/get_custom_schema.sql
2018-04-06 17:09:44,954: Parsing adapters/bigquery.sql
2018-04-06 17:09:44,959: Parsing adapters/common.sql
2018-04-06 17:09:44,981: Parsing adapters/redshift.sql
2018-04-06 17:09:45,004: Parsing adapters/postgres.sql
2018-04-06 17:09:45,007: Parsing schema_tests/relationships.sql
2018-04-06 17:09:45,009: Parsing schema_tests/not_null.sql
2018-04-06 17:09:45,011: Parsing schema_tests/unique.sql
2018-04-06 17:09:45,013: Parsing schema_tests/accepted_values.sql
2018-04-06 17:09:45,020: Parsing model.compology.fl_empty_groups
2018-04-06 17:09:45,022: Parsing model.compology.location_history
2018-04-06 17:09:45,024: Parsing model.compology.post_history
2018-04-06 17:09:45,026: Parsing model.compology.fl_level_at_service
2018-04-06 17:09:45,031: Found 42 macros, 0 analyses, 0 archives, 0 tests, 4 models, 0 operations
2018-04-06 17:09:45,034: 
2018-04-06 17:09:45,036: Acquiring new postgres connection "master".
2018-04-06 17:09:45,036: Opening a new connection (0 currently allocated)
2018-04-06 17:09:45,042: Using postgres connection "master".
2018-04-06 17:09:45,043: On master: select distinct nspname from pg_namespace
2018-04-06 17:09:45,044: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 17:09:45,047: Using postgres connection "master".
2018-04-06 17:09:45,047: On master: BEGIN
2018-04-06 17:09:45,048: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:09:45,048: On master: COMMIT
2018-04-06 17:09:45,048: Using postgres connection "master".
2018-04-06 17:09:45,049: On master: COMMIT
2018-04-06 17:09:45,049: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:09:45,054: 17:09:45 | Concurrency: 1 threads (target='dev')
2018-04-06 17:09:45,054: 17:09:45 | 
2018-04-06 17:09:45,055: Using postgres connection "master".
2018-04-06 17:09:45,055: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:09:45,057: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:09:45,061: 17:09:45 | 1 of 1 START table model dbt_clarice.fl_level_at_service............. [RUN]
2018-04-06 17:09:45,062: Compiling model.compology.fl_level_at_service
2018-04-06 17:09:45,068: Writing injected SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:09:45,070: Acquiring new postgres connection "fl_level_at_service".
2018-04-06 17:09:45,070: Opening a new connection (1 currently allocated)
2018-04-06 17:09:45,075: Using postgres connection "fl_level_at_service".
2018-04-06 17:09:45,075: On fl_level_at_service: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:09:45,078: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:09:45,080: Writing runtime SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:09:45,082: Using postgres connection "fl_level_at_service".
2018-04-06 17:09:45,082: On fl_level_at_service: BEGIN
2018-04-06 17:09:45,082: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:09:45,082: Using postgres connection "fl_level_at_service".
2018-04-06 17:09:45,083: On fl_level_at_service: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_level_at_service__dbt_tmp" as (
    

with empty_groups as (
  select *
  from "dbt_clarice"."fl_empty_groups"
  where empty_group_end is not null
), no_camera_blocked as (
  select dumpster_id, org_id, post_timestamp, agg_level
  from "dbt_clarice"."post_history"
  where container_type = 'front load'
  and agg_level is not null
), posts_with_empty_groups as (
  select ncb.*,
  lag(ncb.agg_level) over (partition by ncb.dumpster_id, eg.empty_group order by ncb.post_timestamp asc) as "lag_level",
  eg.empty_group
  from post_history ph
  left join empty_groups eg
  on (ncb.dumpster_id = eg.dumpster_id
    and ncb.post_timestamp > eg.empty_group_start
    and ncb.post_timestamp <= eg.empty_group_end)
  where eg.empty_group_end is not null
), max_level as (
  select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
  peg.empty_group,
  max(peg.agg_level) over (partition by peg.dumpster_id, peg.empty_group) as "max_level"
  from posts_with_empty_groups peg
  order by peg.dumpster_id, peg.empty_group
)
select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
peg.org_id,
peg.empty_group,
peg.post_timestamp,
peg.raw_device_data_id,
peg.agg_level as "level_at_service",
peg.lag_level as "level_prior_to_service",
ml.max_level as "max_level_before_service"
from posts_with_empty_groups peg
left join max_level ml
on (peg.dumpster_id = ml.dumpster_id and peg.empty_group = ml.empty_group)
order by peg.dumpster_id, peg.empty_group, peg.post_timestamp desc
  );
2018-04-06 17:09:45,083: Postgres error: relation "post_history" does not exist
LINE 25:   from post_history ph
                ^

2018-04-06 17:09:45,083: On fl_level_at_service: ROLLBACK
2018-04-06 17:09:45,084: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1508b25e10>], 'label': '97c682ec-e964-4ce2-97ca-dc81b06e44a8'}
2018-04-06 17:09:45,417: 17:09:45 | 1 of 1 ERROR creating table model dbt_clarice.fl_level_at_service.... [ERROR in 0.02s]
2018-04-06 17:09:45,478: Using postgres connection "master".
2018-04-06 17:09:45,478: On master: BEGIN
2018-04-06 17:09:45,479: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:09:45,479: On master: COMMIT
2018-04-06 17:09:45,479: Using postgres connection "master".
2018-04-06 17:09:45,479: On master: COMMIT
2018-04-06 17:09:45,479: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:09:45,479: 17:09:45 | 
2018-04-06 17:09:45,480: 17:09:45 | Finished running 1 table models in 0.45s.
2018-04-06 17:09:45,480: Connection 'master' was left open.
2018-04-06 17:09:45,480: 
2018-04-06 17:09:45,480: Completed with 1 errors:
2018-04-06 17:09:45,481: 
2018-04-06 17:09:45,481: Database Error in model fl_level_at_service (models/fl_level_at_service.sql)
2018-04-06 17:09:45,481:   relation "post_history" does not exist
2018-04-06 17:09:45,481:   LINE 25:   from post_history ph
2018-04-06 17:09:45,481:                   ^
2018-04-06 17:09:45,482:   compiled SQL at target/run/compology/fl_level_at_service.sql
2018-04-06 17:09:45,482: 
Done. PASS=0 ERROR=1 SKIP=0 TOTAL=1
2018-04-06 17:09:45,482: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105368710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a8e2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1508b8bdd0>], 'label': 'end'}
2018-04-06 17:09:45,885: Flushing usage events
2018-04-06 17:10:24,065: Tracking: tracking
2018-04-06 17:10:24,065: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1507d1bb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1507d1ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1507d1bd50>], 'label': 'start'}
2018-04-06 17:10:24,440: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 17:10:24,454: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 17:10:24,455: Parsing core.sql
2018-04-06 17:10:24,468: Parsing materializations/view.sql
2018-04-06 17:10:24,486: Parsing materializations/bigquery.sql
2018-04-06 17:10:24,501: Parsing materializations/wrapper.sql
2018-04-06 17:10:24,504: Parsing materializations/helpers.sql
2018-04-06 17:10:24,524: Parsing materializations/table.sql
2018-04-06 17:10:24,544: Parsing materializations/archive.sql
2018-04-06 17:10:24,580: Parsing materializations/incremental.sql
2018-04-06 17:10:24,610: Parsing etc/get_custom_schema.sql
2018-04-06 17:10:24,616: Parsing adapters/bigquery.sql
2018-04-06 17:10:24,621: Parsing adapters/common.sql
2018-04-06 17:10:24,644: Parsing adapters/redshift.sql
2018-04-06 17:10:24,667: Parsing adapters/postgres.sql
2018-04-06 17:10:24,671: Parsing schema_tests/relationships.sql
2018-04-06 17:10:24,673: Parsing schema_tests/not_null.sql
2018-04-06 17:10:24,675: Parsing schema_tests/unique.sql
2018-04-06 17:10:24,677: Parsing schema_tests/accepted_values.sql
2018-04-06 17:10:24,684: Parsing model.compology.fl_empty_groups
2018-04-06 17:10:24,686: Parsing model.compology.location_history
2018-04-06 17:10:24,688: Parsing model.compology.post_history
2018-04-06 17:10:24,690: Parsing model.compology.fl_level_at_service
2018-04-06 17:10:24,695: Found 42 macros, 0 analyses, 0 archives, 0 tests, 4 models, 0 operations
2018-04-06 17:10:24,698: 
2018-04-06 17:10:24,701: Acquiring new postgres connection "master".
2018-04-06 17:10:24,701: Opening a new connection (0 currently allocated)
2018-04-06 17:10:24,706: Using postgres connection "master".
2018-04-06 17:10:24,706: On master: select distinct nspname from pg_namespace
2018-04-06 17:10:24,708: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 17:10:24,711: Using postgres connection "master".
2018-04-06 17:10:24,711: On master: BEGIN
2018-04-06 17:10:24,711: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:10:24,711: On master: COMMIT
2018-04-06 17:10:24,711: Using postgres connection "master".
2018-04-06 17:10:24,711: On master: COMMIT
2018-04-06 17:10:24,712: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:10:24,717: 17:10:24 | Concurrency: 1 threads (target='dev')
2018-04-06 17:10:24,717: 17:10:24 | 
2018-04-06 17:10:24,717: Using postgres connection "master".
2018-04-06 17:10:24,718: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:10:24,720: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:10:24,725: 17:10:24 | 1 of 1 START table model dbt_clarice.fl_level_at_service............. [RUN]
2018-04-06 17:10:24,726: Compiling model.compology.fl_level_at_service
2018-04-06 17:10:24,736: Writing injected SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:10:24,737: Acquiring new postgres connection "fl_level_at_service".
2018-04-06 17:10:24,737: Opening a new connection (1 currently allocated)
2018-04-06 17:10:24,742: Using postgres connection "fl_level_at_service".
2018-04-06 17:10:24,742: On fl_level_at_service: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:10:24,746: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:10:24,748: Writing runtime SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:10:24,749: Using postgres connection "fl_level_at_service".
2018-04-06 17:10:24,749: On fl_level_at_service: BEGIN
2018-04-06 17:10:24,750: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:10:24,750: Using postgres connection "fl_level_at_service".
2018-04-06 17:10:24,750: On fl_level_at_service: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_level_at_service__dbt_tmp" as (
    

with empty_groups as (
  select *
  from "dbt_clarice"."fl_empty_groups"
  where empty_group_end is not null
), no_camera_blocked as (
  select dumpster_id, org_id, post_timestamp, agg_level
  from "dbt_clarice"."post_history"
  where container_type = 'front load'
  and agg_level is not null
), posts_with_empty_groups as (
  select ncb.*,
  lag(ncb.agg_level) over (partition by ncb.dumpster_id, eg.empty_group order by ncb.post_timestamp asc) as "lag_level",
  eg.empty_group
  from no_camera_blocked ncb
  left join empty_groups eg
  on (ncb.dumpster_id = eg.dumpster_id
    and ncb.post_timestamp > eg.empty_group_start
    and ncb.post_timestamp <= eg.empty_group_end)
  where eg.empty_group_end is not null
), max_level as (
  select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
  peg.empty_group,
  max(peg.agg_level) over (partition by peg.dumpster_id, peg.empty_group) as "max_level"
  from posts_with_empty_groups peg
  order by peg.dumpster_id, peg.empty_group
)
select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
peg.org_id,
peg.empty_group,
peg.post_timestamp,
peg.raw_device_data_id,
peg.agg_level as "level_at_service",
peg.lag_level as "level_prior_to_service",
ml.max_level as "max_level_before_service"
from posts_with_empty_groups peg
left join max_level ml
on (peg.dumpster_id = ml.dumpster_id and peg.empty_group = ml.empty_group)
order by peg.dumpster_id, peg.empty_group, peg.post_timestamp desc
  );
2018-04-06 17:10:24,754: Postgres error: column eg.empty_group does not exist
LINE 24:   eg.empty_group
           ^
HINT:  Perhaps you meant to reference the column "eg.empty_group_id".

2018-04-06 17:10:24,754: On fl_level_at_service: ROLLBACK
2018-04-06 17:10:24,755: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1507de4e10>], 'label': '4e1331b1-a45b-4fe5-a90b-b57f35851575'}
2018-04-06 17:10:25,091: 17:10:25 | 1 of 1 ERROR creating table model dbt_clarice.fl_level_at_service.... [ERROR in 0.03s]
2018-04-06 17:10:25,134: Using postgres connection "master".
2018-04-06 17:10:25,134: On master: BEGIN
2018-04-06 17:10:25,135: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:10:25,135: On master: COMMIT
2018-04-06 17:10:25,135: Using postgres connection "master".
2018-04-06 17:10:25,135: On master: COMMIT
2018-04-06 17:10:25,135: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:10:25,136: 17:10:25 | 
2018-04-06 17:10:25,136: 17:10:25 | Finished running 1 table models in 0.44s.
2018-04-06 17:10:25,136: Connection 'master' was left open.
2018-04-06 17:10:25,136: 
2018-04-06 17:10:25,137: Completed with 1 errors:
2018-04-06 17:10:25,137: 
2018-04-06 17:10:25,137: Database Error in model fl_level_at_service (models/fl_level_at_service.sql)
2018-04-06 17:10:25,137:   column eg.empty_group does not exist
2018-04-06 17:10:25,137:   LINE 24:   eg.empty_group
2018-04-06 17:10:25,137:              ^
2018-04-06 17:10:25,138:   HINT:  Perhaps you meant to reference the column "eg.empty_group_id".
2018-04-06 17:10:25,138:   compiled SQL at target/run/compology/fl_level_at_service.sql
2018-04-06 17:10:25,138: 
Done. PASS=0 ERROR=1 SKIP=0 TOTAL=1
2018-04-06 17:10:25,138: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10461d710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d4d2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1507e4add0>], 'label': 'end'}
2018-04-06 17:10:25,470: Flushing usage events
2018-04-06 17:10:57,066: Tracking: tracking
2018-04-06 17:10:57,067: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113357b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113357a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113357d50>], 'label': 'start'}
2018-04-06 17:10:57,446: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 17:10:57,460: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 17:10:57,462: Parsing core.sql
2018-04-06 17:10:57,475: Parsing materializations/view.sql
2018-04-06 17:10:57,492: Parsing materializations/bigquery.sql
2018-04-06 17:10:57,507: Parsing materializations/wrapper.sql
2018-04-06 17:10:57,510: Parsing materializations/helpers.sql
2018-04-06 17:10:57,530: Parsing materializations/table.sql
2018-04-06 17:10:57,550: Parsing materializations/archive.sql
2018-04-06 17:10:57,584: Parsing materializations/incremental.sql
2018-04-06 17:10:57,613: Parsing etc/get_custom_schema.sql
2018-04-06 17:10:57,620: Parsing adapters/bigquery.sql
2018-04-06 17:10:57,625: Parsing adapters/common.sql
2018-04-06 17:10:57,654: Parsing adapters/redshift.sql
2018-04-06 17:10:57,676: Parsing adapters/postgres.sql
2018-04-06 17:10:57,680: Parsing schema_tests/relationships.sql
2018-04-06 17:10:57,682: Parsing schema_tests/not_null.sql
2018-04-06 17:10:57,684: Parsing schema_tests/unique.sql
2018-04-06 17:10:57,686: Parsing schema_tests/accepted_values.sql
2018-04-06 17:10:57,693: Parsing model.compology.fl_empty_groups
2018-04-06 17:10:57,695: Parsing model.compology.location_history
2018-04-06 17:10:57,697: Parsing model.compology.post_history
2018-04-06 17:10:57,699: Parsing model.compology.fl_level_at_service
2018-04-06 17:10:57,704: Found 42 macros, 0 analyses, 0 archives, 0 tests, 4 models, 0 operations
2018-04-06 17:10:57,707: 
2018-04-06 17:10:57,710: Acquiring new postgres connection "master".
2018-04-06 17:10:57,710: Opening a new connection (0 currently allocated)
2018-04-06 17:10:57,715: Using postgres connection "master".
2018-04-06 17:10:57,715: On master: select distinct nspname from pg_namespace
2018-04-06 17:10:57,717: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 17:10:57,720: Using postgres connection "master".
2018-04-06 17:10:57,720: On master: BEGIN
2018-04-06 17:10:57,721: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:10:57,721: On master: COMMIT
2018-04-06 17:10:57,721: Using postgres connection "master".
2018-04-06 17:10:57,722: On master: COMMIT
2018-04-06 17:10:57,722: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:10:57,727: 17:10:57 | Concurrency: 1 threads (target='dev')
2018-04-06 17:10:57,727: 17:10:57 | 
2018-04-06 17:10:57,728: Using postgres connection "master".
2018-04-06 17:10:57,728: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:10:57,731: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:10:57,735: 17:10:57 | 1 of 1 START table model dbt_clarice.fl_level_at_service............. [RUN]
2018-04-06 17:10:57,735: Compiling model.compology.fl_level_at_service
2018-04-06 17:10:57,744: Writing injected SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:10:57,746: Acquiring new postgres connection "fl_level_at_service".
2018-04-06 17:10:57,746: Opening a new connection (1 currently allocated)
2018-04-06 17:10:57,752: Using postgres connection "fl_level_at_service".
2018-04-06 17:10:57,752: On fl_level_at_service: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:10:57,756: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:10:57,759: Writing runtime SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:10:57,759: Using postgres connection "fl_level_at_service".
2018-04-06 17:10:57,760: On fl_level_at_service: BEGIN
2018-04-06 17:10:57,760: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:10:57,760: Using postgres connection "fl_level_at_service".
2018-04-06 17:10:57,760: On fl_level_at_service: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_level_at_service__dbt_tmp" as (
    

with empty_groups as (
  select *
  from "dbt_clarice"."fl_empty_groups"
  where empty_group_end is not null
), no_camera_blocked as (
  select dumpster_id, org_id, post_timestamp, agg_level
  from "dbt_clarice"."post_history"
  where container_type = 'front load'
  and agg_level is not null
), posts_with_empty_groups as (
  select ncb.*,
  lag(ncb.agg_level) over (partition by ncb.dumpster_id, eg.empty_group_id order by ncb.post_timestamp asc) as "lag_level",
  eg.empty_group_id
  from no_camera_blocked ncb
  left join empty_groups eg
  on (ncb.dumpster_id = eg.dumpster_id
    and ncb.post_timestamp > eg.empty_group_start
    and ncb.post_timestamp <= eg.empty_group_end)
  where eg.empty_group_end is not null
), max_level as (
  select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
  peg.empty_group,
  max(peg.agg_level) over (partition by peg.dumpster_id, peg.empty_group) as "max_level"
  from posts_with_empty_groups peg
  order by peg.dumpster_id, peg.empty_group
)
select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
peg.org_id,
peg.empty_group,
peg.post_timestamp,
peg.raw_device_data_id,
peg.agg_level as "level_at_service",
peg.lag_level as "level_prior_to_service",
ml.max_level as "max_level_before_service"
from posts_with_empty_groups peg
left join max_level ml
on (peg.dumpster_id = ml.dumpster_id and peg.empty_group = ml.empty_group)
order by peg.dumpster_id, peg.empty_group, peg.post_timestamp desc
  );
2018-04-06 17:10:57,762: Postgres error: column peg.empty_group does not exist
LINE 33:   peg.empty_group,
           ^
HINT:  Perhaps you meant to reference the column "peg.empty_group_id".

2018-04-06 17:10:57,762: On fl_level_at_service: ROLLBACK
2018-04-06 17:10:57,762: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113420e10>], 'label': 'cd98e6d2-c6c7-447e-ac73-9347b8992308'}
2018-04-06 17:10:58,093: 17:10:58 | 1 of 1 ERROR creating table model dbt_clarice.fl_level_at_service.... [ERROR in 0.03s]
2018-04-06 17:10:58,152: Using postgres connection "master".
2018-04-06 17:10:58,152: On master: BEGIN
2018-04-06 17:10:58,152: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:10:58,152: On master: COMMIT
2018-04-06 17:10:58,152: Using postgres connection "master".
2018-04-06 17:10:58,153: On master: COMMIT
2018-04-06 17:10:58,153: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:10:58,153: 17:10:58 | 
2018-04-06 17:10:58,153: 17:10:58 | Finished running 1 table models in 0.45s.
2018-04-06 17:10:58,153: Connection 'master' was left open.
2018-04-06 17:10:58,154: 
2018-04-06 17:10:58,154: Completed with 1 errors:
2018-04-06 17:10:58,154: 
2018-04-06 17:10:58,154: Database Error in model fl_level_at_service (models/fl_level_at_service.sql)
2018-04-06 17:10:58,154:   column peg.empty_group does not exist
2018-04-06 17:10:58,155:   LINE 33:   peg.empty_group,
2018-04-06 17:10:58,155:              ^
2018-04-06 17:10:58,155:   HINT:  Perhaps you meant to reference the column "peg.empty_group_id".
2018-04-06 17:10:58,155:   compiled SQL at target/run/compology/fl_level_at_service.sql
2018-04-06 17:10:58,155: 
Done. PASS=0 ERROR=1 SKIP=0 TOTAL=1
2018-04-06 17:10:58,156: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110384710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ab42d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113486dd0>], 'label': 'end'}
2018-04-06 17:10:58,489: Flushing usage events
2018-04-06 17:11:58,228: Tracking: tracking
2018-04-06 17:11:58,228: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109162b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109162a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109162d50>], 'label': 'start'}
2018-04-06 17:11:58,609: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 17:11:58,622: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 17:11:58,624: Parsing core.sql
2018-04-06 17:11:58,637: Parsing materializations/view.sql
2018-04-06 17:11:58,653: Parsing materializations/bigquery.sql
2018-04-06 17:11:58,669: Parsing materializations/wrapper.sql
2018-04-06 17:11:58,672: Parsing materializations/helpers.sql
2018-04-06 17:11:58,691: Parsing materializations/table.sql
2018-04-06 17:11:58,711: Parsing materializations/archive.sql
2018-04-06 17:11:58,745: Parsing materializations/incremental.sql
2018-04-06 17:11:58,775: Parsing etc/get_custom_schema.sql
2018-04-06 17:11:58,780: Parsing adapters/bigquery.sql
2018-04-06 17:11:58,785: Parsing adapters/common.sql
2018-04-06 17:11:58,807: Parsing adapters/redshift.sql
2018-04-06 17:11:58,830: Parsing adapters/postgres.sql
2018-04-06 17:11:58,833: Parsing schema_tests/relationships.sql
2018-04-06 17:11:58,835: Parsing schema_tests/not_null.sql
2018-04-06 17:11:58,837: Parsing schema_tests/unique.sql
2018-04-06 17:11:58,839: Parsing schema_tests/accepted_values.sql
2018-04-06 17:11:58,846: Parsing model.compology.fl_empty_groups
2018-04-06 17:11:58,848: Parsing model.compology.location_history
2018-04-06 17:11:58,849: Parsing model.compology.post_history
2018-04-06 17:11:58,852: Parsing model.compology.fl_level_at_service
2018-04-06 17:11:58,857: Found 42 macros, 0 analyses, 0 archives, 0 tests, 4 models, 0 operations
2018-04-06 17:11:58,860: 
2018-04-06 17:11:58,863: Acquiring new postgres connection "master".
2018-04-06 17:11:58,863: Opening a new connection (0 currently allocated)
2018-04-06 17:11:58,868: Using postgres connection "master".
2018-04-06 17:11:58,868: On master: select distinct nspname from pg_namespace
2018-04-06 17:11:58,870: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 17:11:58,873: Using postgres connection "master".
2018-04-06 17:11:58,873: On master: BEGIN
2018-04-06 17:11:58,874: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:11:58,874: On master: COMMIT
2018-04-06 17:11:58,874: Using postgres connection "master".
2018-04-06 17:11:58,874: On master: COMMIT
2018-04-06 17:11:58,874: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:11:58,880: 17:11:58 | Concurrency: 1 threads (target='dev')
2018-04-06 17:11:58,880: 17:11:58 | 
2018-04-06 17:11:58,880: Using postgres connection "master".
2018-04-06 17:11:58,880: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:11:58,883: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:11:58,887: 17:11:58 | 1 of 1 START table model dbt_clarice.fl_level_at_service............. [RUN]
2018-04-06 17:11:58,887: Compiling model.compology.fl_level_at_service
2018-04-06 17:11:58,894: Writing injected SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:11:58,895: Acquiring new postgres connection "fl_level_at_service".
2018-04-06 17:11:58,895: Opening a new connection (1 currently allocated)
2018-04-06 17:11:58,900: Using postgres connection "fl_level_at_service".
2018-04-06 17:11:58,900: On fl_level_at_service: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:11:58,904: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:11:58,906: Writing runtime SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:11:58,907: Using postgres connection "fl_level_at_service".
2018-04-06 17:11:58,907: On fl_level_at_service: BEGIN
2018-04-06 17:11:58,908: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:11:58,908: Using postgres connection "fl_level_at_service".
2018-04-06 17:11:58,908: On fl_level_at_service: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_level_at_service__dbt_tmp" as (
    

with empty_groups as (
  select *
  from "dbt_clarice"."fl_empty_groups"
  where empty_group_end is not null
), no_camera_blocked as (
  select dumpster_id, org_id, post_timestamp, agg_level
  from "dbt_clarice"."post_history"
  where container_type = 'front load'
  and agg_level is not null
), posts_with_empty_groups as (
  select ncb.*,
  lag(ncb.agg_level) over (partition by ncb.dumpster_id, eg.empty_group_id order by ncb.post_timestamp asc) as "lag_level",
  eg.empty_group_id
  from no_camera_blocked ncb
  left join empty_groups eg
  on (ncb.dumpster_id = eg.dumpster_id
    and ncb.post_timestamp > eg.empty_group_start
    and ncb.post_timestamp <= eg.empty_group_end)
  where eg.empty_group_end is not null
), max_level as (
  select distinct on (dumpster_id, empty_group_id) dumpster_id,
  empty_group_id,
  max(agg_level) over (partition by dumpster_id, empty_group_id) as "max_level"
  from posts_with_empty_groups
  order by dumpster_id, empty_group_id
)
select distinct on (peg.dumpster_id, peg.empty_group) peg.dumpster_id,
peg.org_id,
peg.empty_group,
peg.post_timestamp,
peg.raw_device_data_id,
peg.agg_level as "level_at_service",
peg.lag_level as "level_prior_to_service",
ml.max_level as "max_level_before_service"
from posts_with_empty_groups peg
left join max_level ml
on (peg.dumpster_id = ml.dumpster_id and peg.empty_group = ml.empty_group)
order by peg.dumpster_id, peg.empty_group, peg.post_timestamp desc
  );
2018-04-06 17:11:58,912: Postgres error: column peg.empty_group does not exist
LINE 48: on (peg.dumpster_id = ml.dumpster_id and peg.empty_group = m...
                                                  ^
HINT:  Perhaps you meant to reference the column "peg.empty_group_id".

2018-04-06 17:11:58,912: On fl_level_at_service: ROLLBACK
2018-04-06 17:11:58,912: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10922be10>], 'label': 'c4dab7f5-11b3-4fd4-bbce-3c44acf22c43'}
2018-04-06 17:11:59,251: 17:11:59 | 1 of 1 ERROR creating table model dbt_clarice.fl_level_at_service.... [ERROR in 0.03s]
2018-04-06 17:11:59,307: Using postgres connection "master".
2018-04-06 17:11:59,308: On master: BEGIN
2018-04-06 17:11:59,308: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:11:59,309: On master: COMMIT
2018-04-06 17:11:59,309: Using postgres connection "master".
2018-04-06 17:11:59,309: On master: COMMIT
2018-04-06 17:11:59,310: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:11:59,310: 17:11:59 | 
2018-04-06 17:11:59,310: 17:11:59 | Finished running 1 table models in 0.45s.
2018-04-06 17:11:59,310: Connection 'master' was left open.
2018-04-06 17:11:59,311: 
2018-04-06 17:11:59,311: Completed with 1 errors:
2018-04-06 17:11:59,311: 
2018-04-06 17:11:59,311: Database Error in model fl_level_at_service (models/fl_level_at_service.sql)
2018-04-06 17:11:59,311:   column peg.empty_group does not exist
2018-04-06 17:11:59,312:   LINE 48: on (peg.dumpster_id = ml.dumpster_id and peg.empty_group = m...
2018-04-06 17:11:59,312:                                                     ^
2018-04-06 17:11:59,312:   HINT:  Perhaps you meant to reference the column "peg.empty_group_id".
2018-04-06 17:11:59,313:   compiled SQL at target/run/compology/fl_level_at_service.sql
2018-04-06 17:11:59,313: 
Done. PASS=0 ERROR=1 SKIP=0 TOTAL=1
2018-04-06 17:11:59,313: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10618f710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078bf2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109291dd0>], 'label': 'end'}
2018-04-06 17:11:59,650: Flushing usage events
2018-04-06 17:12:42,017: Tracking: tracking
2018-04-06 17:12:42,017: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x151135eb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x151135ea10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x151135ed50>], 'label': 'start'}
2018-04-06 17:12:42,391: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 17:12:42,404: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 17:12:42,406: Parsing core.sql
2018-04-06 17:12:42,419: Parsing materializations/view.sql
2018-04-06 17:12:42,436: Parsing materializations/bigquery.sql
2018-04-06 17:12:42,451: Parsing materializations/wrapper.sql
2018-04-06 17:12:42,454: Parsing materializations/helpers.sql
2018-04-06 17:12:42,474: Parsing materializations/table.sql
2018-04-06 17:12:42,495: Parsing materializations/archive.sql
2018-04-06 17:12:42,529: Parsing materializations/incremental.sql
2018-04-06 17:12:42,558: Parsing etc/get_custom_schema.sql
2018-04-06 17:12:42,564: Parsing adapters/bigquery.sql
2018-04-06 17:12:42,569: Parsing adapters/common.sql
2018-04-06 17:12:42,591: Parsing adapters/redshift.sql
2018-04-06 17:12:42,614: Parsing adapters/postgres.sql
2018-04-06 17:12:42,617: Parsing schema_tests/relationships.sql
2018-04-06 17:12:42,620: Parsing schema_tests/not_null.sql
2018-04-06 17:12:42,621: Parsing schema_tests/unique.sql
2018-04-06 17:12:42,623: Parsing schema_tests/accepted_values.sql
2018-04-06 17:12:42,630: Parsing model.compology.fl_empty_groups
2018-04-06 17:12:42,632: Parsing model.compology.location_history
2018-04-06 17:12:42,634: Parsing model.compology.post_history
2018-04-06 17:12:42,636: Parsing model.compology.fl_level_at_service
2018-04-06 17:12:42,641: Found 42 macros, 0 analyses, 0 archives, 0 tests, 4 models, 0 operations
2018-04-06 17:12:42,644: 
2018-04-06 17:12:42,647: Acquiring new postgres connection "master".
2018-04-06 17:12:42,647: Opening a new connection (0 currently allocated)
2018-04-06 17:12:42,652: Using postgres connection "master".
2018-04-06 17:12:42,652: On master: select distinct nspname from pg_namespace
2018-04-06 17:12:42,654: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 17:12:42,657: Using postgres connection "master".
2018-04-06 17:12:42,657: On master: BEGIN
2018-04-06 17:12:42,658: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:12:42,658: On master: COMMIT
2018-04-06 17:12:42,658: Using postgres connection "master".
2018-04-06 17:12:42,658: On master: COMMIT
2018-04-06 17:12:42,658: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:12:42,664: 17:12:42 | Concurrency: 1 threads (target='dev')
2018-04-06 17:12:42,664: 17:12:42 | 
2018-04-06 17:12:42,664: Using postgres connection "master".
2018-04-06 17:12:42,664: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:12:42,667: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:12:42,671: 17:12:42 | 1 of 1 START table model dbt_clarice.fl_level_at_service............. [RUN]
2018-04-06 17:12:42,671: Compiling model.compology.fl_level_at_service
2018-04-06 17:12:42,677: Writing injected SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:12:42,678: Acquiring new postgres connection "fl_level_at_service".
2018-04-06 17:12:42,678: Opening a new connection (1 currently allocated)
2018-04-06 17:12:42,684: Using postgres connection "fl_level_at_service".
2018-04-06 17:12:42,684: On fl_level_at_service: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:12:42,688: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:12:42,692: Writing runtime SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:12:42,693: Using postgres connection "fl_level_at_service".
2018-04-06 17:12:42,693: On fl_level_at_service: BEGIN
2018-04-06 17:12:42,694: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:12:42,694: Using postgres connection "fl_level_at_service".
2018-04-06 17:12:42,694: On fl_level_at_service: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_level_at_service__dbt_tmp" as (
    

with empty_groups as (
  select *
  from "dbt_clarice"."fl_empty_groups"
  where empty_group_end is not null
), no_camera_blocked as (
  select dumpster_id, org_id, post_timestamp, agg_level
  from "dbt_clarice"."post_history"
  where container_type = 'front load'
  and agg_level is not null
), posts_with_empty_groups as (
  select ncb.*,
  lag(ncb.agg_level) over (partition by ncb.dumpster_id, eg.empty_group_id order by ncb.post_timestamp asc) as "lag_level",
  eg.empty_group_id
  from no_camera_blocked ncb
  left join empty_groups eg
  on (ncb.dumpster_id = eg.dumpster_id
    and ncb.post_timestamp > eg.empty_group_start
    and ncb.post_timestamp <= eg.empty_group_end)
  where eg.empty_group_end is not null
), max_level as (
  select distinct on (dumpster_id, empty_group_id) dumpster_id,
  empty_group_id,
  max(agg_level) over (partition by dumpster_id, empty_group_id) as "max_level"
  from posts_with_empty_groups
  order by dumpster_id, empty_group_id
)
select distinct on (peg.dumpster_id, peg.empty_group_id) peg.dumpster_id,
peg.org_id,
peg.empty_group_id,
peg.post_timestamp,
peg.raw_device_data_id,
peg.agg_level as "level_at_service",
peg.lag_level as "level_prior_to_service",
ml.max_level as "max_level_before_service"
from posts_with_empty_groups peg
left join max_level ml
on (peg.dumpster_id = ml.dumpster_id and peg.empty_group_id = ml.empty_group_id)
order by peg.dumpster_id, peg.empty_group_id, peg.post_timestamp desc
  );
2018-04-06 17:12:42,696: Postgres error: column peg.raw_device_data_id does not exist
LINE 42: peg.raw_device_data_id,
         ^

2018-04-06 17:12:42,696: On fl_level_at_service: ROLLBACK
2018-04-06 17:12:42,697: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1511427e10>], 'label': '76631613-0930-475c-8a65-2166d7de92c3'}
2018-04-06 17:12:43,025: 17:12:43 | 1 of 1 ERROR creating table model dbt_clarice.fl_level_at_service.... [ERROR in 0.03s]
2018-04-06 17:12:43,085: Using postgres connection "master".
2018-04-06 17:12:43,085: On master: BEGIN
2018-04-06 17:12:43,085: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:12:43,085: On master: COMMIT
2018-04-06 17:12:43,086: Using postgres connection "master".
2018-04-06 17:12:43,086: On master: COMMIT
2018-04-06 17:12:43,086: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:12:43,086: 17:12:43 | 
2018-04-06 17:12:43,086: 17:12:43 | Finished running 1 table models in 0.44s.
2018-04-06 17:12:43,086: Connection 'master' was left open.
2018-04-06 17:12:43,087: 
2018-04-06 17:12:43,087: Completed with 1 errors:
2018-04-06 17:12:43,087: 
2018-04-06 17:12:43,087: Database Error in model fl_level_at_service (models/fl_level_at_service.sql)
2018-04-06 17:12:43,088:   column peg.raw_device_data_id does not exist
2018-04-06 17:12:43,088:   LINE 42: peg.raw_device_data_id,
2018-04-06 17:12:43,088:            ^
2018-04-06 17:12:43,088:   compiled SQL at target/run/compology/fl_level_at_service.sql
2018-04-06 17:12:43,088: 
Done. PASS=0 ERROR=1 SKIP=0 TOTAL=1
2018-04-06 17:12:43,089: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc62710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3902d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x151148ddd0>], 'label': 'end'}
2018-04-06 17:12:43,426: Flushing usage events
2018-04-06 17:13:08,561: Tracking: tracking
2018-04-06 17:13:08,561: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1513c93b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1513c93a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1513c93d50>], 'label': 'start'}
2018-04-06 17:13:08,904: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 17:13:08,917: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 17:13:08,919: Parsing core.sql
2018-04-06 17:13:08,932: Parsing materializations/view.sql
2018-04-06 17:13:08,948: Parsing materializations/bigquery.sql
2018-04-06 17:13:08,963: Parsing materializations/wrapper.sql
2018-04-06 17:13:08,966: Parsing materializations/helpers.sql
2018-04-06 17:13:08,985: Parsing materializations/table.sql
2018-04-06 17:13:09,006: Parsing materializations/archive.sql
2018-04-06 17:13:09,040: Parsing materializations/incremental.sql
2018-04-06 17:13:09,068: Parsing etc/get_custom_schema.sql
2018-04-06 17:13:09,074: Parsing adapters/bigquery.sql
2018-04-06 17:13:09,079: Parsing adapters/common.sql
2018-04-06 17:13:09,101: Parsing adapters/redshift.sql
2018-04-06 17:13:09,123: Parsing adapters/postgres.sql
2018-04-06 17:13:09,126: Parsing schema_tests/relationships.sql
2018-04-06 17:13:09,129: Parsing schema_tests/not_null.sql
2018-04-06 17:13:09,130: Parsing schema_tests/unique.sql
2018-04-06 17:13:09,132: Parsing schema_tests/accepted_values.sql
2018-04-06 17:13:09,139: Parsing model.compology.fl_empty_groups
2018-04-06 17:13:09,141: Parsing model.compology.location_history
2018-04-06 17:13:09,143: Parsing model.compology.post_history
2018-04-06 17:13:09,145: Parsing model.compology.fl_level_at_service
2018-04-06 17:13:09,150: Found 42 macros, 0 analyses, 0 archives, 0 tests, 4 models, 0 operations
2018-04-06 17:13:09,153: 
2018-04-06 17:13:09,156: Acquiring new postgres connection "master".
2018-04-06 17:13:09,156: Opening a new connection (0 currently allocated)
2018-04-06 17:13:09,161: Using postgres connection "master".
2018-04-06 17:13:09,161: On master: select distinct nspname from pg_namespace
2018-04-06 17:13:09,163: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 17:13:09,166: Using postgres connection "master".
2018-04-06 17:13:09,166: On master: BEGIN
2018-04-06 17:13:09,166: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:13:09,167: On master: COMMIT
2018-04-06 17:13:09,167: Using postgres connection "master".
2018-04-06 17:13:09,167: On master: COMMIT
2018-04-06 17:13:09,167: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:13:09,172: 17:13:09 | Concurrency: 1 threads (target='dev')
2018-04-06 17:13:09,172: 17:13:09 | 
2018-04-06 17:13:09,173: Using postgres connection "master".
2018-04-06 17:13:09,173: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:13:09,175: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:13:09,179: 17:13:09 | 1 of 1 START table model dbt_clarice.fl_level_at_service............. [RUN]
2018-04-06 17:13:09,180: Compiling model.compology.fl_level_at_service
2018-04-06 17:13:09,186: Writing injected SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:13:09,188: Acquiring new postgres connection "fl_level_at_service".
2018-04-06 17:13:09,189: Opening a new connection (1 currently allocated)
2018-04-06 17:13:09,195: Using postgres connection "fl_level_at_service".
2018-04-06 17:13:09,195: On fl_level_at_service: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:13:09,200: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:13:09,202: Writing runtime SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:13:09,203: Using postgres connection "fl_level_at_service".
2018-04-06 17:13:09,204: On fl_level_at_service: BEGIN
2018-04-06 17:13:09,204: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:13:09,204: Using postgres connection "fl_level_at_service".
2018-04-06 17:13:09,204: On fl_level_at_service: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_level_at_service__dbt_tmp" as (
    

with empty_groups as (
  select *
  from "dbt_clarice"."fl_empty_groups"
  where empty_group_end is not null
), no_camera_blocked as (
  select dumpster_id, org_id, post_timestamp, agg_level
  from "dbt_clarice"."post_history"
  where container_type = 'front load'
  and agg_level is not null
), posts_with_empty_groups as (
  select ncb.*,
  lag(ncb.agg_level) over (partition by ncb.dumpster_id, eg.empty_group_id order by ncb.post_timestamp asc) as "lag_level",
  eg.empty_group_id
  from no_camera_blocked ncb
  left join empty_groups eg
  on (ncb.dumpster_id = eg.dumpster_id
    and ncb.post_timestamp > eg.empty_group_start
    and ncb.post_timestamp <= eg.empty_group_end)
  where eg.empty_group_end is not null
), max_level as (
  select distinct on (dumpster_id, empty_group_id) dumpster_id,
  empty_group_id,
  max(agg_level) over (partition by dumpster_id, empty_group_id) as "max_level"
  from posts_with_empty_groups
  order by dumpster_id, empty_group_id
)
select distinct on (peg.dumpster_id, peg.empty_group_id) peg.dumpster_id,
peg.org_id,
peg.empty_group_id,
peg.post_timestamp,
peg.end_raw_device_data_id,
peg.agg_level as "level_at_service",
peg.lag_level as "level_prior_to_service",
ml.max_level as "max_level_before_service"
from posts_with_empty_groups peg
left join max_level ml
on (peg.dumpster_id = ml.dumpster_id and peg.empty_group_id = ml.empty_group_id)
order by peg.dumpster_id, peg.empty_group_id, peg.post_timestamp desc
  );
2018-04-06 17:13:09,206: Postgres error: column peg.end_raw_device_data_id does not exist
LINE 42: peg.end_raw_device_data_id,
         ^

2018-04-06 17:13:09,206: On fl_level_at_service: ROLLBACK
2018-04-06 17:13:09,206: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1513d5ce10>], 'label': '7f273f37-9616-46ca-ae05-806c1f9f0a56'}
2018-04-06 17:13:09,544: 17:13:09 | 1 of 1 ERROR creating table model dbt_clarice.fl_level_at_service.... [ERROR in 0.03s]
2018-04-06 17:13:09,596: Using postgres connection "master".
2018-04-06 17:13:09,596: On master: BEGIN
2018-04-06 17:13:09,597: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:13:09,597: On master: COMMIT
2018-04-06 17:13:09,597: Using postgres connection "master".
2018-04-06 17:13:09,597: On master: COMMIT
2018-04-06 17:13:09,597: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:13:09,597: 17:13:09 | 
2018-04-06 17:13:09,598: 17:13:09 | Finished running 1 table models in 0.44s.
2018-04-06 17:13:09,598: Connection 'master' was left open.
2018-04-06 17:13:09,598: 
2018-04-06 17:13:09,598: Completed with 1 errors:
2018-04-06 17:13:09,599: 
2018-04-06 17:13:09,599: Database Error in model fl_level_at_service (models/fl_level_at_service.sql)
2018-04-06 17:13:09,599:   column peg.end_raw_device_data_id does not exist
2018-04-06 17:13:09,599:   LINE 42: peg.end_raw_device_data_id,
2018-04-06 17:13:09,599:            ^
2018-04-06 17:13:09,600:   compiled SQL at target/run/compology/fl_level_at_service.sql
2018-04-06 17:13:09,600: 
Done. PASS=0 ERROR=1 SKIP=0 TOTAL=1
2018-04-06 17:13:09,600: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110595710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cc52d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1513dc2dd0>], 'label': 'end'}
2018-04-06 17:13:09,972: Flushing usage events
2018-04-06 17:13:32,654: Tracking: tracking
2018-04-06 17:13:32,654: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1514f46b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1514f46a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1514f46d50>], 'label': 'start'}
2018-04-06 17:13:33,026: Loading dependency project from /anaconda2/lib/python2.7/site-packages/dbt/include
2018-04-06 17:13:33,039: Loading dependency project from /Users/clarice/dbt_local/dbt_modules
2018-04-06 17:13:33,041: Parsing core.sql
2018-04-06 17:13:33,054: Parsing materializations/view.sql
2018-04-06 17:13:33,070: Parsing materializations/bigquery.sql
2018-04-06 17:13:33,085: Parsing materializations/wrapper.sql
2018-04-06 17:13:33,088: Parsing materializations/helpers.sql
2018-04-06 17:13:33,108: Parsing materializations/table.sql
2018-04-06 17:13:33,128: Parsing materializations/archive.sql
2018-04-06 17:13:33,162: Parsing materializations/incremental.sql
2018-04-06 17:13:33,191: Parsing etc/get_custom_schema.sql
2018-04-06 17:13:33,197: Parsing adapters/bigquery.sql
2018-04-06 17:13:33,202: Parsing adapters/common.sql
2018-04-06 17:13:33,224: Parsing adapters/redshift.sql
2018-04-06 17:13:33,246: Parsing adapters/postgres.sql
2018-04-06 17:13:33,249: Parsing schema_tests/relationships.sql
2018-04-06 17:13:33,251: Parsing schema_tests/not_null.sql
2018-04-06 17:13:33,253: Parsing schema_tests/unique.sql
2018-04-06 17:13:33,255: Parsing schema_tests/accepted_values.sql
2018-04-06 17:13:33,262: Parsing model.compology.fl_empty_groups
2018-04-06 17:13:33,264: Parsing model.compology.location_history
2018-04-06 17:13:33,266: Parsing model.compology.post_history
2018-04-06 17:13:33,268: Parsing model.compology.fl_level_at_service
2018-04-06 17:13:33,273: Found 42 macros, 0 analyses, 0 archives, 0 tests, 4 models, 0 operations
2018-04-06 17:13:33,276: 
2018-04-06 17:13:33,278: Acquiring new postgres connection "master".
2018-04-06 17:13:33,279: Opening a new connection (0 currently allocated)
2018-04-06 17:13:33,284: Using postgres connection "master".
2018-04-06 17:13:33,284: On master: select distinct nspname from pg_namespace
2018-04-06 17:13:33,286: SQL status: SELECT 11 in 0.00 seconds
2018-04-06 17:13:33,289: Using postgres connection "master".
2018-04-06 17:13:33,289: On master: BEGIN
2018-04-06 17:13:33,289: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:13:33,289: On master: COMMIT
2018-04-06 17:13:33,289: Using postgres connection "master".
2018-04-06 17:13:33,289: On master: COMMIT
2018-04-06 17:13:33,290: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:13:33,297: 17:13:33 | Concurrency: 1 threads (target='dev')
2018-04-06 17:13:33,297: 17:13:33 | 
2018-04-06 17:13:33,297: Using postgres connection "master".
2018-04-06 17:13:33,298: On master: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:13:33,300: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:13:33,305: 17:13:33 | 1 of 1 START table model dbt_clarice.fl_level_at_service............. [RUN]
2018-04-06 17:13:33,306: Compiling model.compology.fl_level_at_service
2018-04-06 17:13:33,313: Writing injected SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:13:33,314: Acquiring new postgres connection "fl_level_at_service".
2018-04-06 17:13:33,314: Opening a new connection (1 currently allocated)
2018-04-06 17:13:33,319: Using postgres connection "fl_level_at_service".
2018-04-06 17:13:33,319: On fl_level_at_service: select tablename as name, 'table' as type from pg_tables
        where schemaname in ('dbt_clarice')
        union all
        select viewname as name, 'view' as type from pg_views
        where schemaname in ('dbt_clarice')
2018-04-06 17:13:33,324: SQL status: SELECT 3 in 0.00 seconds
2018-04-06 17:13:33,327: Writing runtime SQL for node "model.compology.fl_level_at_service"
2018-04-06 17:13:33,327: Using postgres connection "fl_level_at_service".
2018-04-06 17:13:33,327: On fl_level_at_service: BEGIN
2018-04-06 17:13:33,328: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:13:33,328: Using postgres connection "fl_level_at_service".
2018-04-06 17:13:33,328: On fl_level_at_service: 
  
    
  

  
    
  create  table
    "dbt_clarice"."fl_level_at_service__dbt_tmp" as (
    

with empty_groups as (
  select *
  from "dbt_clarice"."fl_empty_groups"
  where empty_group_end is not null
), no_camera_blocked as (
  select dumpster_id, org_id, post_timestamp, agg_level
  from "dbt_clarice"."post_history"
  where container_type = 'front load'
  and agg_level is not null
), posts_with_empty_groups as (
  select ncb.*,
  lag(ncb.agg_level) over (partition by ncb.dumpster_id, eg.empty_group_id order by ncb.post_timestamp asc) as "lag_level",
  eg.empty_group_id
  from no_camera_blocked ncb
  left join empty_groups eg
  on (ncb.dumpster_id = eg.dumpster_id
    and ncb.post_timestamp > eg.empty_group_start
    and ncb.post_timestamp <= eg.empty_group_end)
  where eg.empty_group_end is not null
), max_level as (
  select distinct on (dumpster_id, empty_group_id) dumpster_id,
  empty_group_id,
  max(agg_level) over (partition by dumpster_id, empty_group_id) as "max_level"
  from posts_with_empty_groups
  order by dumpster_id, empty_group_id
)
select distinct on (peg.dumpster_id, peg.empty_group_id) peg.dumpster_id,
peg.org_id,
peg.empty_group_id,
peg.post_timestamp,
peg.agg_level as "level_at_service",
peg.lag_level as "level_prior_to_service",
ml.max_level as "max_level_before_service"
from posts_with_empty_groups peg
left join max_level ml
on (peg.dumpster_id = ml.dumpster_id and peg.empty_group_id = ml.empty_group_id)
order by peg.dumpster_id, peg.empty_group_id, peg.post_timestamp desc
  );
2018-04-06 17:18:07,161: SQL status: SELECT 172058 in 273.83 seconds
2018-04-06 17:18:07,164: Using postgres connection "fl_level_at_service".
2018-04-06 17:18:07,164: On fl_level_at_service: alter table "dbt_clarice"."fl_level_at_service__dbt_tmp" rename to "fl_level_at_service"
2018-04-06 17:18:07,168: SQL status: ALTER TABLE in 0.00 seconds
2018-04-06 17:18:07,169: On fl_level_at_service: COMMIT
2018-04-06 17:18:07,169: Using postgres connection "fl_level_at_service".
2018-04-06 17:18:07,169: On fl_level_at_service: COMMIT
2018-04-06 17:18:07,171: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:18:07,172: Sending event: {'category': 'dbt', 'action': 'run_model', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15150730d0>], 'label': '5b3ca78f-79cc-4498-a785-1239fcb05119'}
2018-04-06 17:18:07,547: 17:18:07 | 1 of 1 OK created table model dbt_clarice.fl_level_at_service........ [SELECT 172058 in 273.87s]
2018-04-06 17:18:07,602: Using postgres connection "master".
2018-04-06 17:18:07,602: On master: BEGIN
2018-04-06 17:18:07,602: SQL status: BEGIN in 0.00 seconds
2018-04-06 17:18:07,602: On master: COMMIT
2018-04-06 17:18:07,603: Using postgres connection "master".
2018-04-06 17:18:07,603: On master: COMMIT
2018-04-06 17:18:07,603: SQL status: COMMIT in 0.00 seconds
2018-04-06 17:18:07,603: 17:18:07 | 
2018-04-06 17:18:07,603: 17:18:07 | Finished running 1 table models in 274.33s.
2018-04-06 17:18:07,604: Connection 'master' was left open.
2018-04-06 17:18:07,604: 
2018-04-06 17:18:07,606: Completed successfully
2018-04-06 17:18:07,606: 
Done. PASS=1 ERROR=0 SKIP=0 TOTAL=1
2018-04-06 17:18:07,606: Sending event: {'category': 'dbt', 'action': 'invocation', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11184d710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f782d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1514f36d10>], 'label': 'end'}
2018-04-06 17:18:07,939: Flushing usage events
